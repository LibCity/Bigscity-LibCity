{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06eb49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Embedding.GNN_Based_Layers as GNN\n",
    "import ST_backbone.RNN_Based_Models as RNN\n",
    "import sys\n",
    "sys.path.append('/home/zwt/Bigscity-LibCity')\n",
    "from logging import getLogger\n",
    "from libcity.model.abstract_traffic_state_model import AbstractTrafficStateModel\n",
    "from libcity.model import loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9389dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class AGCRN(AbstractTrafficStateModel):\n",
    "    def __init__(self, config, data_feature):\n",
    "        self.num_nodes = data_feature.get('num_nodes', 1)\n",
    "        self.feature_dim = data_feature.get('feature_dim', 1)\n",
    "        config['num_nodes'] = self.num_nodes\n",
    "        config['feature_dim'] = self.feature_dim\n",
    "\n",
    "        super().__init__(config, data_feature)\n",
    "        self.input_window = config.get('input_window', 1)\n",
    "        self.output_window = config.get('output_window', 1)\n",
    "        self.output_dim = self.data_feature.get('output_dim', 1)\n",
    "        self.hidden_dim = config.get('rnn_units', 64)\n",
    "        self.embed_dim = config.get('embed_dim', 10)\n",
    "\n",
    "#         self.gcn=GNN.AVWGCN(self.feature_dim,self.hidden_dim,config.get('cheb_order', 2),self.num_nodes,self.embed_dim)\n",
    "#         self.gcn_encode=GNN.TimedistributedGCN(self.gcn)\n",
    "        self.trnn=RNN.TemporalGRU(config,0,0)\n",
    "        \n",
    "        self.end_conv = nn.Conv2d(1, self.output_window * self.output_dim, kernel_size=(1, self.hidden_dim), bias=True)\n",
    "\n",
    "        self.device = config.get('device', torch.device('cpu'))\n",
    "        self._logger = getLogger()\n",
    "        self._scaler = self.data_feature.get('scaler')\n",
    "        self._init_parameters()\n",
    "    \n",
    "    def _init_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "            else:\n",
    "                nn.init.uniform_(p)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # source: B, T_1, N, D\n",
    "        # target: B, T_2, N, D\n",
    "        source = batch['X']\n",
    "        \n",
    "        batch_size=source.shape[0]\n",
    "                \n",
    "        output = self.trnn(source)  # B, T, N, hidden\n",
    "        output = output[:, -1:, :, :]                                       # B, 1, N, hidden\n",
    "\n",
    "        # CNN based predictor\n",
    "        output = self.end_conv(output)                           # B, T*C, N, 1\n",
    "        output = output.squeeze(-1).reshape(-1, self.output_window, self.output_dim, self.num_nodes)\n",
    "        output = output.permute(0, 1, 3, 2)                      # B, T, N, C\n",
    "        return output\n",
    "    \n",
    "    def calculate_loss(self, batch):\n",
    "        y_true = batch['y']\n",
    "        y_predicted = self.predict(batch)\n",
    "        y_true = self._scaler.inverse_transform(y_true[..., :self.output_dim])\n",
    "        y_predicted = self._scaler.inverse_transform(y_predicted[..., :self.output_dim])\n",
    "        return loss.masked_mae_torch(y_predicted, y_true, 0)\n",
    "\n",
    "    def predict(self, batch):\n",
    "        return self.forward(batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2157ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:17:06,062 - INFO - Log directory: ./libcity/log\n",
      "2021-12-03 15:17:06,806 - INFO - Loaded file METR_LA.geo, num_nodes=207\n",
      "2021-12-03 15:17:06,815 - INFO - set_weight_link_or_dist: dist\n",
      "2021-12-03 15:17:06,816 - INFO - init_weight_inf_or_zero: inf\n",
      "2021-12-03 15:17:06,848 - INFO - Loaded file METR_LA.rel, shape=(207, 207)\n",
      "2021-12-03 15:17:06,849 - INFO - Loading ./libcity/cache/dataset_cache/point_based_METR_LA_12_12_0.7_0.1_standard_64_False_False_False_False.npz\n",
      "2021-12-03 15:17:09,960 - INFO - train\tx: (23974, 12, 207, 1), y: (23974, 12, 207, 1)\n",
      "2021-12-03 15:17:09,963 - INFO - eval\tx: (3425, 12, 207, 1), y: (3425, 12, 207, 1)\n",
      "2021-12-03 15:17:09,963 - INFO - test\tx: (6850, 12, 207, 1), y: (6850, 12, 207, 1)\n",
      "2021-12-03 15:17:10,312 - INFO - StandardScaler mean: 54.40592829587626, std: 19.493739270573098\n",
      "2021-12-03 15:17:10,313 - INFO - NoneScaler\n",
      "375 23974 (12, 207, 1) (12, 207, 1) 64\n",
      "54 3425 (12, 207, 1) (12, 207, 1) 64\n",
      "108 6850 (12, 207, 1) (12, 207, 1) 64\n",
      "(207, 207)\n",
      "inf\n",
      "2021-12-03 15:17:15,785 - INFO - AGCRN(\n",
      "  (trnn): TemporalGRU(\n",
      "    (gru_cell): AGCRNCell(\n",
      "      (gate): AVWGCN()\n",
      "      (update): AVWGCN()\n",
      "    )\n",
      "  )\n",
      "  (end_conv): Conv2d(1, 12, kernel_size=(1, 64), stride=(1, 1))\n",
      ")\n",
      "2021-12-03 15:17:15,786 - INFO - trnn.gru_cell.gate.weights_pool\ttorch.Size([10, 2, 65, 128])\tcuda:0\tTrue\n",
      "2021-12-03 15:17:15,787 - INFO - trnn.gru_cell.gate.bias_pool\ttorch.Size([10, 128])\tcuda:0\tTrue\n",
      "2021-12-03 15:17:15,787 - INFO - trnn.gru_cell.gate.node_embeddings\ttorch.Size([207, 10])\tcuda:0\tTrue\n",
      "2021-12-03 15:17:15,788 - INFO - trnn.gru_cell.update.weights_pool\ttorch.Size([10, 2, 65, 64])\tcuda:0\tTrue\n",
      "2021-12-03 15:17:15,790 - INFO - trnn.gru_cell.update.bias_pool\ttorch.Size([10, 64])\tcuda:0\tTrue\n",
      "2021-12-03 15:17:15,791 - INFO - trnn.gru_cell.update.node_embeddings\ttorch.Size([207, 10])\tcuda:0\tTrue\n",
      "2021-12-03 15:17:15,792 - INFO - end_conv.weight\ttorch.Size([12, 1, 1, 64])\tcuda:0\tTrue\n",
      "2021-12-03 15:17:15,793 - INFO - end_conv.bias\ttorch.Size([12])\tcuda:0\tTrue\n",
      "2021-12-03 15:17:15,794 - INFO - Total parameter numbers: 256440\n",
      "2021-12-03 15:17:15,794 - INFO - You select `adam` optimizer.\n",
      "2021-12-03 15:17:15,795 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2021-12-03 15:17:15,796 - INFO - Start training ...\n",
      "2021-12-03 15:17:15,797 - INFO - num_batches:375\n",
      "2021-12-03 15:17:35,857 - INFO - epoch complete!\n",
      "2021-12-03 15:17:35,860 - INFO - evaluating now!\n",
      "2021-12-03 15:17:37,186 - INFO - Epoch [0/100] train_loss: 4.1844, val_loss: 3.3993, lr: 0.003000, 21.39s\n",
      "2021-12-03 15:17:37,206 - INFO - Saved model at 0\n",
      "2021-12-03 15:17:37,207 - INFO - Val loss decrease from inf to 3.3993, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch0.tar\n",
      "2021-12-03 15:17:57,061 - INFO - epoch complete!\n",
      "2021-12-03 15:17:57,064 - INFO - evaluating now!\n",
      "2021-12-03 15:17:58,436 - INFO - Epoch [1/100] train_loss: 3.4311, val_loss: 3.2206, lr: 0.003000, 21.23s\n",
      "2021-12-03 15:17:58,455 - INFO - Saved model at 1\n",
      "2021-12-03 15:17:58,456 - INFO - Val loss decrease from 3.3993 to 3.2206, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch1.tar\n",
      "2021-12-03 15:18:19,390 - INFO - epoch complete!\n",
      "2021-12-03 15:18:19,393 - INFO - evaluating now!\n",
      "2021-12-03 15:18:20,803 - INFO - Epoch [2/100] train_loss: 3.2616, val_loss: 3.1027, lr: 0.003000, 22.35s\n",
      "2021-12-03 15:18:20,821 - INFO - Saved model at 2\n",
      "2021-12-03 15:18:20,822 - INFO - Val loss decrease from 3.2206 to 3.1027, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch2.tar\n",
      "2021-12-03 15:18:43,672 - INFO - epoch complete!\n",
      "2021-12-03 15:18:43,676 - INFO - evaluating now!\n",
      "2021-12-03 15:18:45,033 - INFO - Epoch [3/100] train_loss: 3.1405, val_loss: 3.0223, lr: 0.003000, 24.21s\n",
      "2021-12-03 15:18:45,054 - INFO - Saved model at 3\n",
      "2021-12-03 15:18:45,055 - INFO - Val loss decrease from 3.1027 to 3.0223, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch3.tar\n",
      "2021-12-03 15:19:09,803 - INFO - epoch complete!\n",
      "2021-12-03 15:19:09,806 - INFO - evaluating now!\n",
      "2021-12-03 15:19:11,217 - INFO - Epoch [4/100] train_loss: 3.0703, val_loss: 2.9939, lr: 0.003000, 26.16s\n",
      "2021-12-03 15:19:11,235 - INFO - Saved model at 4\n",
      "2021-12-03 15:19:11,236 - INFO - Val loss decrease from 3.0223 to 2.9939, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch4.tar\n",
      "2021-12-03 15:19:31,544 - INFO - epoch complete!\n",
      "2021-12-03 15:19:31,547 - INFO - evaluating now!\n",
      "2021-12-03 15:19:32,907 - INFO - Epoch [5/100] train_loss: 3.0205, val_loss: 2.9593, lr: 0.003000, 21.67s\n",
      "2021-12-03 15:19:32,926 - INFO - Saved model at 5\n",
      "2021-12-03 15:19:32,928 - INFO - Val loss decrease from 2.9939 to 2.9593, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch5.tar\n",
      "2021-12-03 15:19:53,637 - INFO - epoch complete!\n",
      "2021-12-03 15:19:53,640 - INFO - evaluating now!\n",
      "2021-12-03 15:19:55,045 - INFO - Epoch [6/100] train_loss: 2.9837, val_loss: 2.9281, lr: 0.003000, 22.12s\n",
      "2021-12-03 15:19:55,067 - INFO - Saved model at 6\n",
      "2021-12-03 15:19:55,068 - INFO - Val loss decrease from 2.9593 to 2.9281, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch6.tar\n",
      "2021-12-03 15:20:17,866 - INFO - epoch complete!\n",
      "2021-12-03 15:20:17,869 - INFO - evaluating now!\n",
      "2021-12-03 15:20:19,240 - INFO - Epoch [7/100] train_loss: 2.9471, val_loss: 2.9136, lr: 0.003000, 24.17s\n",
      "2021-12-03 15:20:19,263 - INFO - Saved model at 7\n",
      "2021-12-03 15:20:19,264 - INFO - Val loss decrease from 2.9281 to 2.9136, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch7.tar\n",
      "2021-12-03 15:20:39,171 - INFO - epoch complete!\n",
      "2021-12-03 15:20:39,174 - INFO - evaluating now!\n",
      "2021-12-03 15:20:40,492 - INFO - Epoch [8/100] train_loss: 2.9231, val_loss: 2.9076, lr: 0.003000, 21.23s\n",
      "2021-12-03 15:20:40,511 - INFO - Saved model at 8\n",
      "2021-12-03 15:20:40,512 - INFO - Val loss decrease from 2.9136 to 2.9076, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch8.tar\n",
      "2021-12-03 15:21:01,248 - INFO - epoch complete!\n",
      "2021-12-03 15:21:01,251 - INFO - evaluating now!\n",
      "2021-12-03 15:21:02,673 - INFO - Epoch [9/100] train_loss: 2.8941, val_loss: 2.9342, lr: 0.003000, 22.16s\n",
      "2021-12-03 15:21:22,237 - INFO - epoch complete!\n",
      "2021-12-03 15:21:22,240 - INFO - evaluating now!\n",
      "2021-12-03 15:21:23,614 - INFO - Epoch [10/100] train_loss: 2.8700, val_loss: 2.9097, lr: 0.003000, 20.94s\n",
      "2021-12-03 15:21:43,863 - INFO - epoch complete!\n",
      "2021-12-03 15:21:43,865 - INFO - evaluating now!\n",
      "2021-12-03 15:21:45,237 - INFO - Epoch [11/100] train_loss: 2.8487, val_loss: 2.9044, lr: 0.003000, 21.62s\n",
      "2021-12-03 15:21:45,256 - INFO - Saved model at 11\n",
      "2021-12-03 15:21:45,257 - INFO - Val loss decrease from 2.9076 to 2.9044, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch11.tar\n",
      "2021-12-03 15:22:06,979 - INFO - epoch complete!\n",
      "2021-12-03 15:22:06,982 - INFO - evaluating now!\n",
      "2021-12-03 15:22:08,397 - INFO - Epoch [12/100] train_loss: 2.8280, val_loss: 2.8988, lr: 0.003000, 23.14s\n",
      "2021-12-03 15:22:08,417 - INFO - Saved model at 12\n",
      "2021-12-03 15:22:08,417 - INFO - Val loss decrease from 2.9044 to 2.8988, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch12.tar\n",
      "2021-12-03 15:22:33,216 - INFO - epoch complete!\n",
      "2021-12-03 15:22:33,219 - INFO - evaluating now!\n",
      "2021-12-03 15:22:34,569 - INFO - Epoch [13/100] train_loss: 2.8130, val_loss: 2.9150, lr: 0.003000, 26.15s\n",
      "2021-12-03 15:22:57,676 - INFO - epoch complete!\n",
      "2021-12-03 15:22:57,679 - INFO - evaluating now!\n",
      "2021-12-03 15:22:59,087 - INFO - Epoch [14/100] train_loss: 2.7931, val_loss: 2.9122, lr: 0.003000, 24.52s\n",
      "2021-12-03 15:23:20,045 - INFO - epoch complete!\n",
      "2021-12-03 15:23:20,048 - INFO - evaluating now!\n",
      "2021-12-03 15:23:21,473 - INFO - Epoch [15/100] train_loss: 2.7783, val_loss: 2.9168, lr: 0.003000, 22.38s\n",
      "2021-12-03 15:23:43,944 - INFO - epoch complete!\n",
      "2021-12-03 15:23:43,948 - INFO - evaluating now!\n",
      "2021-12-03 15:23:45,298 - INFO - Epoch [16/100] train_loss: 2.7616, val_loss: 2.8940, lr: 0.003000, 23.82s\n",
      "2021-12-03 15:23:45,319 - INFO - Saved model at 16\n",
      "2021-12-03 15:23:45,320 - INFO - Val loss decrease from 2.8988 to 2.8940, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch16.tar\n",
      "2021-12-03 15:24:06,594 - INFO - epoch complete!\n",
      "2021-12-03 15:24:06,597 - INFO - evaluating now!\n",
      "2021-12-03 15:24:08,033 - INFO - Epoch [17/100] train_loss: 2.7474, val_loss: 2.9142, lr: 0.003000, 22.71s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:24:28,760 - INFO - epoch complete!\n",
      "2021-12-03 15:24:28,763 - INFO - evaluating now!\n",
      "2021-12-03 15:24:30,135 - INFO - Epoch [18/100] train_loss: 2.7341, val_loss: 2.8841, lr: 0.003000, 22.10s\n",
      "2021-12-03 15:24:30,154 - INFO - Saved model at 18\n",
      "2021-12-03 15:24:30,155 - INFO - Val loss decrease from 2.8940 to 2.8841, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch18.tar\n",
      "2021-12-03 15:24:53,551 - INFO - epoch complete!\n",
      "2021-12-03 15:24:53,555 - INFO - evaluating now!\n",
      "2021-12-03 15:24:54,959 - INFO - Epoch [19/100] train_loss: 2.7212, val_loss: 2.9116, lr: 0.003000, 24.80s\n",
      "2021-12-03 15:25:16,166 - INFO - epoch complete!\n",
      "2021-12-03 15:25:16,169 - INFO - evaluating now!\n",
      "2021-12-03 15:25:17,493 - INFO - Epoch [20/100] train_loss: 2.7100, val_loss: 2.9225, lr: 0.003000, 22.53s\n",
      "2021-12-03 15:25:41,683 - INFO - epoch complete!\n",
      "2021-12-03 15:25:41,686 - INFO - evaluating now!\n",
      "2021-12-03 15:25:43,253 - INFO - Epoch [21/100] train_loss: 2.6982, val_loss: 2.9247, lr: 0.003000, 25.76s\n",
      "2021-12-03 15:26:04,298 - INFO - epoch complete!\n",
      "2021-12-03 15:26:04,301 - INFO - evaluating now!\n",
      "2021-12-03 15:26:05,621 - INFO - Epoch [22/100] train_loss: 2.6843, val_loss: 2.9059, lr: 0.003000, 22.37s\n",
      "2021-12-03 15:26:30,632 - INFO - epoch complete!\n",
      "2021-12-03 15:26:30,635 - INFO - evaluating now!\n",
      "2021-12-03 15:26:32,013 - INFO - Epoch [23/100] train_loss: 2.6743, val_loss: 2.9072, lr: 0.003000, 26.39s\n",
      "2021-12-03 15:26:51,587 - INFO - epoch complete!\n",
      "2021-12-03 15:26:51,590 - INFO - evaluating now!\n",
      "2021-12-03 15:26:52,947 - INFO - Epoch [24/100] train_loss: 2.6649, val_loss: 2.9159, lr: 0.003000, 20.93s\n",
      "2021-12-03 15:27:14,155 - INFO - epoch complete!\n",
      "2021-12-03 15:27:14,158 - INFO - evaluating now!\n",
      "2021-12-03 15:27:15,553 - INFO - Epoch [25/100] train_loss: 2.6558, val_loss: 2.9198, lr: 0.003000, 22.60s\n",
      "2021-12-03 15:27:34,606 - INFO - epoch complete!\n",
      "2021-12-03 15:27:34,609 - INFO - evaluating now!\n",
      "2021-12-03 15:27:35,994 - INFO - Epoch [26/100] train_loss: 2.6453, val_loss: 2.9069, lr: 0.003000, 20.44s\n",
      "2021-12-03 15:28:00,032 - INFO - epoch complete!\n",
      "2021-12-03 15:28:00,035 - INFO - evaluating now!\n",
      "2021-12-03 15:28:01,432 - INFO - Epoch [27/100] train_loss: 2.6382, val_loss: 2.9029, lr: 0.003000, 25.44s\n",
      "2021-12-03 15:28:22,406 - INFO - epoch complete!\n",
      "2021-12-03 15:28:22,409 - INFO - evaluating now!\n",
      "2021-12-03 15:28:23,796 - INFO - Epoch [28/100] train_loss: 2.6313, val_loss: 2.9465, lr: 0.003000, 22.36s\n",
      "2021-12-03 15:28:43,529 - INFO - epoch complete!\n",
      "2021-12-03 15:28:43,532 - INFO - evaluating now!\n",
      "2021-12-03 15:28:44,924 - INFO - Epoch [29/100] train_loss: 2.6221, val_loss: 2.9425, lr: 0.003000, 21.13s\n",
      "2021-12-03 15:29:04,552 - INFO - epoch complete!\n",
      "2021-12-03 15:29:04,555 - INFO - evaluating now!\n",
      "2021-12-03 15:29:05,944 - INFO - Epoch [30/100] train_loss: 2.6162, val_loss: 2.9163, lr: 0.003000, 21.02s\n",
      "2021-12-03 15:29:26,466 - INFO - epoch complete!\n",
      "2021-12-03 15:29:26,469 - INFO - evaluating now!\n",
      "2021-12-03 15:29:27,855 - INFO - Epoch [31/100] train_loss: 2.6100, val_loss: 2.9254, lr: 0.003000, 21.91s\n",
      "2021-12-03 15:29:47,481 - INFO - epoch complete!\n",
      "2021-12-03 15:29:47,484 - INFO - evaluating now!\n",
      "2021-12-03 15:29:48,873 - INFO - Epoch [32/100] train_loss: 2.6030, val_loss: 2.9374, lr: 0.003000, 21.02s\n",
      "2021-12-03 15:30:09,378 - INFO - epoch complete!\n",
      "2021-12-03 15:30:09,381 - INFO - evaluating now!\n",
      "2021-12-03 15:30:10,788 - INFO - Epoch [33/100] train_loss: 2.5973, val_loss: 2.9298, lr: 0.003000, 21.91s\n",
      "2021-12-03 15:30:32,945 - INFO - epoch complete!\n",
      "2021-12-03 15:30:32,948 - INFO - evaluating now!\n",
      "2021-12-03 15:30:34,340 - INFO - Epoch [34/100] train_loss: 2.5897, val_loss: 2.9415, lr: 0.003000, 23.55s\n",
      "2021-12-03 15:30:56,785 - INFO - epoch complete!\n",
      "2021-12-03 15:30:56,787 - INFO - evaluating now!\n",
      "2021-12-03 15:30:58,198 - INFO - Epoch [35/100] train_loss: 2.5850, val_loss: 2.9542, lr: 0.003000, 23.86s\n",
      "2021-12-03 15:31:20,667 - INFO - epoch complete!\n",
      "2021-12-03 15:31:20,670 - INFO - evaluating now!\n",
      "2021-12-03 15:31:22,012 - INFO - Epoch [36/100] train_loss: 2.5821, val_loss: 2.9564, lr: 0.003000, 23.81s\n",
      "2021-12-03 15:31:42,102 - INFO - epoch complete!\n",
      "2021-12-03 15:31:42,104 - INFO - evaluating now!\n",
      "2021-12-03 15:31:43,488 - INFO - Epoch [37/100] train_loss: 2.5725, val_loss: 2.9366, lr: 0.003000, 21.47s\n",
      "2021-12-03 15:32:03,910 - INFO - epoch complete!\n",
      "2021-12-03 15:32:03,913 - INFO - evaluating now!\n",
      "2021-12-03 15:32:05,336 - INFO - Epoch [38/100] train_loss: 2.5672, val_loss: 2.9496, lr: 0.003000, 21.84s\n",
      "2021-12-03 15:32:24,948 - INFO - epoch complete!\n",
      "2021-12-03 15:32:24,951 - INFO - evaluating now!\n",
      "2021-12-03 15:32:26,369 - INFO - Epoch [39/100] train_loss: 2.5649, val_loss: 2.9260, lr: 0.003000, 21.03s\n",
      "2021-12-03 15:32:46,135 - INFO - epoch complete!\n",
      "2021-12-03 15:32:46,138 - INFO - evaluating now!\n",
      "2021-12-03 15:32:47,516 - INFO - Epoch [40/100] train_loss: 2.5603, val_loss: 2.9630, lr: 0.003000, 21.14s\n",
      "2021-12-03 15:33:12,983 - INFO - epoch complete!\n",
      "2021-12-03 15:33:12,987 - INFO - evaluating now!\n",
      "2021-12-03 15:33:14,387 - INFO - Epoch [41/100] train_loss: 2.5559, val_loss: 2.9570, lr: 0.003000, 26.87s\n",
      "2021-12-03 15:33:37,307 - INFO - epoch complete!\n",
      "2021-12-03 15:33:37,310 - INFO - evaluating now!\n",
      "2021-12-03 15:33:38,711 - INFO - Epoch [42/100] train_loss: 2.5516, val_loss: 2.9457, lr: 0.003000, 24.32s\n",
      "2021-12-03 15:34:04,167 - INFO - epoch complete!\n",
      "2021-12-03 15:34:04,169 - INFO - evaluating now!\n",
      "2021-12-03 15:34:05,853 - INFO - Epoch [43/100] train_loss: 2.5486, val_loss: 2.9591, lr: 0.003000, 27.14s\n",
      "2021-12-03 15:34:25,362 - INFO - epoch complete!\n",
      "2021-12-03 15:34:25,365 - INFO - evaluating now!\n",
      "2021-12-03 15:34:26,780 - INFO - Epoch [44/100] train_loss: 2.5441, val_loss: 2.9803, lr: 0.003000, 20.92s\n",
      "2021-12-03 15:34:48,760 - INFO - epoch complete!\n",
      "2021-12-03 15:34:48,763 - INFO - evaluating now!\n",
      "2021-12-03 15:34:50,072 - INFO - Epoch [45/100] train_loss: 2.5387, val_loss: 2.9523, lr: 0.003000, 23.29s\n",
      "2021-12-03 15:35:11,647 - INFO - epoch complete!\n",
      "2021-12-03 15:35:11,650 - INFO - evaluating now!\n",
      "2021-12-03 15:35:12,978 - INFO - Epoch [46/100] train_loss: 2.5352, val_loss: 2.9470, lr: 0.003000, 22.90s\n",
      "2021-12-03 15:35:36,972 - INFO - epoch complete!\n",
      "2021-12-03 15:35:36,975 - INFO - evaluating now!\n",
      "2021-12-03 15:35:38,372 - INFO - Epoch [47/100] train_loss: 2.5320, val_loss: 2.9591, lr: 0.003000, 25.39s\n",
      "2021-12-03 15:36:00,254 - INFO - epoch complete!\n",
      "2021-12-03 15:36:00,257 - INFO - evaluating now!\n",
      "2021-12-03 15:36:01,603 - INFO - Epoch [48/100] train_loss: 2.5286, val_loss: 2.9669, lr: 0.003000, 23.23s\n",
      "2021-12-03 15:36:23,095 - INFO - epoch complete!\n",
      "2021-12-03 15:36:23,098 - INFO - evaluating now!\n",
      "2021-12-03 15:36:24,509 - INFO - Epoch [49/100] train_loss: 2.5258, val_loss: 2.9548, lr: 0.003000, 22.90s\n",
      "2021-12-03 15:36:45,222 - INFO - epoch complete!\n",
      "2021-12-03 15:36:45,225 - INFO - evaluating now!\n",
      "2021-12-03 15:36:46,665 - INFO - Epoch [50/100] train_loss: 2.5208, val_loss: 2.9545, lr: 0.003000, 22.15s\n",
      "2021-12-03 15:37:07,509 - INFO - epoch complete!\n",
      "2021-12-03 15:37:07,512 - INFO - evaluating now!\n",
      "2021-12-03 15:37:08,889 - INFO - Epoch [51/100] train_loss: 2.5171, val_loss: 2.9348, lr: 0.003000, 22.22s\n",
      "2021-12-03 15:37:29,934 - INFO - epoch complete!\n",
      "2021-12-03 15:37:29,936 - INFO - evaluating now!\n",
      "2021-12-03 15:37:31,318 - INFO - Epoch [52/100] train_loss: 2.5157, val_loss: 2.9524, lr: 0.003000, 22.43s\n",
      "2021-12-03 15:37:52,511 - INFO - epoch complete!\n",
      "2021-12-03 15:37:52,513 - INFO - evaluating now!\n",
      "2021-12-03 15:37:53,907 - INFO - Epoch [53/100] train_loss: 2.5129, val_loss: 2.9832, lr: 0.003000, 22.59s\n",
      "2021-12-03 15:38:18,454 - INFO - epoch complete!\n",
      "2021-12-03 15:38:18,457 - INFO - evaluating now!\n",
      "2021-12-03 15:38:19,858 - INFO - Epoch [54/100] train_loss: 2.5094, val_loss: 2.9805, lr: 0.003000, 25.95s\n",
      "2021-12-03 15:38:39,970 - INFO - epoch complete!\n",
      "2021-12-03 15:38:39,974 - INFO - evaluating now!\n",
      "2021-12-03 15:38:41,381 - INFO - Epoch [55/100] train_loss: 2.5060, val_loss: 2.9699, lr: 0.003000, 21.52s\n",
      "2021-12-03 15:39:02,497 - INFO - epoch complete!\n",
      "2021-12-03 15:39:02,499 - INFO - evaluating now!\n",
      "2021-12-03 15:39:03,903 - INFO - Epoch [56/100] train_loss: 2.5078, val_loss: 2.9469, lr: 0.003000, 22.52s\n",
      "2021-12-03 15:39:25,245 - INFO - epoch complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:39:25,247 - INFO - evaluating now!\n",
      "2021-12-03 15:39:26,580 - INFO - Epoch [57/100] train_loss: 2.5026, val_loss: 2.9717, lr: 0.003000, 22.67s\n",
      "2021-12-03 15:39:44,855 - INFO - epoch complete!\n",
      "2021-12-03 15:39:44,858 - INFO - evaluating now!\n",
      "2021-12-03 15:39:46,268 - INFO - Epoch [58/100] train_loss: 2.4973, val_loss: 2.9696, lr: 0.003000, 19.69s\n",
      "2021-12-03 15:40:06,619 - INFO - epoch complete!\n",
      "2021-12-03 15:40:06,621 - INFO - evaluating now!\n",
      "2021-12-03 15:40:07,988 - INFO - Epoch [59/100] train_loss: 2.4973, val_loss: 2.9687, lr: 0.003000, 21.72s\n",
      "2021-12-03 15:40:28,187 - INFO - epoch complete!\n",
      "2021-12-03 15:40:28,190 - INFO - evaluating now!\n",
      "2021-12-03 15:40:29,558 - INFO - Epoch [60/100] train_loss: 2.4936, val_loss: 2.9748, lr: 0.003000, 21.57s\n",
      "2021-12-03 15:40:54,040 - INFO - epoch complete!\n",
      "2021-12-03 15:40:54,043 - INFO - evaluating now!\n",
      "2021-12-03 15:40:55,388 - INFO - Epoch [61/100] train_loss: 2.4914, val_loss: 3.0012, lr: 0.003000, 25.83s\n",
      "2021-12-03 15:41:16,073 - INFO - epoch complete!\n",
      "2021-12-03 15:41:16,076 - INFO - evaluating now!\n",
      "2021-12-03 15:41:17,464 - INFO - Epoch [62/100] train_loss: 2.4905, val_loss: 2.9861, lr: 0.003000, 22.07s\n",
      "2021-12-03 15:41:38,222 - INFO - epoch complete!\n",
      "2021-12-03 15:41:38,225 - INFO - evaluating now!\n",
      "2021-12-03 15:41:39,574 - INFO - Epoch [63/100] train_loss: 2.4862, val_loss: 2.9612, lr: 0.003000, 22.11s\n",
      "2021-12-03 15:42:00,421 - INFO - epoch complete!\n",
      "2021-12-03 15:42:00,425 - INFO - evaluating now!\n",
      "2021-12-03 15:42:01,800 - INFO - Epoch [64/100] train_loss: 2.4840, val_loss: 2.9837, lr: 0.003000, 22.22s\n",
      "2021-12-03 15:42:21,741 - INFO - epoch complete!\n",
      "2021-12-03 15:42:21,744 - INFO - evaluating now!\n",
      "2021-12-03 15:42:23,120 - INFO - Epoch [65/100] train_loss: 2.4815, val_loss: 2.9776, lr: 0.003000, 21.32s\n",
      "2021-12-03 15:42:43,656 - INFO - epoch complete!\n",
      "2021-12-03 15:42:43,659 - INFO - evaluating now!\n",
      "2021-12-03 15:42:44,985 - INFO - Epoch [66/100] train_loss: 2.4783, val_loss: 2.9668, lr: 0.003000, 21.86s\n",
      "2021-12-03 15:43:05,530 - INFO - epoch complete!\n",
      "2021-12-03 15:43:05,533 - INFO - evaluating now!\n",
      "2021-12-03 15:43:06,940 - INFO - Epoch [67/100] train_loss: 2.4759, val_loss: 2.9837, lr: 0.003000, 21.95s\n",
      "2021-12-03 15:43:29,318 - INFO - epoch complete!\n",
      "2021-12-03 15:43:29,321 - INFO - evaluating now!\n",
      "2021-12-03 15:43:30,766 - INFO - Epoch [68/100] train_loss: 2.4762, val_loss: 2.9769, lr: 0.003000, 23.82s\n",
      "2021-12-03 15:43:51,595 - INFO - epoch complete!\n",
      "2021-12-03 15:43:51,598 - INFO - evaluating now!\n",
      "2021-12-03 15:43:52,990 - INFO - Epoch [69/100] train_loss: 2.4749, val_loss: 2.9802, lr: 0.003000, 22.22s\n",
      "2021-12-03 15:44:13,999 - INFO - epoch complete!\n",
      "2021-12-03 15:44:14,002 - INFO - evaluating now!\n",
      "2021-12-03 15:44:15,389 - INFO - Epoch [70/100] train_loss: 2.4717, val_loss: 2.9705, lr: 0.003000, 22.40s\n",
      "2021-12-03 15:44:36,129 - INFO - epoch complete!\n",
      "2021-12-03 15:44:36,132 - INFO - evaluating now!\n",
      "2021-12-03 15:44:37,452 - INFO - Epoch [71/100] train_loss: 2.4659, val_loss: 2.9804, lr: 0.003000, 22.06s\n",
      "2021-12-03 15:45:00,563 - INFO - epoch complete!\n",
      "2021-12-03 15:45:00,566 - INFO - evaluating now!\n",
      "2021-12-03 15:45:01,905 - INFO - Epoch [72/100] train_loss: 2.4684, val_loss: 2.9875, lr: 0.003000, 24.45s\n",
      "2021-12-03 15:45:26,038 - INFO - epoch complete!\n",
      "2021-12-03 15:45:26,041 - INFO - evaluating now!\n",
      "2021-12-03 15:45:27,400 - INFO - Epoch [73/100] train_loss: 2.4653, val_loss: 2.9953, lr: 0.003000, 25.49s\n",
      "2021-12-03 15:45:50,370 - INFO - epoch complete!\n",
      "2021-12-03 15:45:50,373 - INFO - evaluating now!\n",
      "2021-12-03 15:45:51,840 - INFO - Epoch [74/100] train_loss: 2.4625, val_loss: 2.9952, lr: 0.003000, 24.44s\n",
      "2021-12-03 15:46:13,840 - INFO - epoch complete!\n",
      "2021-12-03 15:46:13,843 - INFO - evaluating now!\n",
      "2021-12-03 15:46:15,245 - INFO - Epoch [75/100] train_loss: 2.4618, val_loss: 2.9727, lr: 0.003000, 23.40s\n",
      "2021-12-03 15:46:38,718 - INFO - epoch complete!\n",
      "2021-12-03 15:46:38,722 - INFO - evaluating now!\n",
      "2021-12-03 15:46:40,129 - INFO - Epoch [76/100] train_loss: 2.4596, val_loss: 2.9888, lr: 0.003000, 24.88s\n",
      "2021-12-03 15:47:02,036 - INFO - epoch complete!\n",
      "2021-12-03 15:47:02,039 - INFO - evaluating now!\n",
      "2021-12-03 15:47:03,392 - INFO - Epoch [77/100] train_loss: 2.4577, val_loss: 2.9892, lr: 0.003000, 23.26s\n",
      "2021-12-03 15:47:24,311 - INFO - epoch complete!\n",
      "2021-12-03 15:47:24,314 - INFO - evaluating now!\n",
      "2021-12-03 15:47:25,704 - INFO - Epoch [78/100] train_loss: 2.4556, val_loss: 2.9877, lr: 0.003000, 22.31s\n",
      "2021-12-03 15:47:45,898 - INFO - epoch complete!\n",
      "2021-12-03 15:47:45,901 - INFO - evaluating now!\n",
      "2021-12-03 15:47:47,299 - INFO - Epoch [79/100] train_loss: 2.4529, val_loss: 3.0009, lr: 0.003000, 21.59s\n",
      "2021-12-03 15:48:07,402 - INFO - epoch complete!\n",
      "2021-12-03 15:48:07,405 - INFO - evaluating now!\n",
      "2021-12-03 15:48:08,821 - INFO - Epoch [80/100] train_loss: 2.4533, val_loss: 2.9869, lr: 0.003000, 21.52s\n",
      "2021-12-03 15:48:29,845 - INFO - epoch complete!\n",
      "2021-12-03 15:48:29,847 - INFO - evaluating now!\n",
      "2021-12-03 15:48:31,222 - INFO - Epoch [81/100] train_loss: 2.4510, val_loss: 2.9975, lr: 0.003000, 22.40s\n",
      "2021-12-03 15:48:54,136 - INFO - epoch complete!\n",
      "2021-12-03 15:48:54,139 - INFO - evaluating now!\n",
      "2021-12-03 15:48:55,571 - INFO - Epoch [82/100] train_loss: 2.4473, val_loss: 2.9892, lr: 0.003000, 24.35s\n",
      "2021-12-03 15:49:16,647 - INFO - epoch complete!\n",
      "2021-12-03 15:49:16,650 - INFO - evaluating now!\n",
      "2021-12-03 15:49:18,063 - INFO - Epoch [83/100] train_loss: 2.4472, val_loss: 3.0000, lr: 0.003000, 22.49s\n",
      "2021-12-03 15:49:38,615 - INFO - epoch complete!\n",
      "2021-12-03 15:49:38,617 - INFO - evaluating now!\n",
      "2021-12-03 15:49:39,999 - INFO - Epoch [84/100] train_loss: 2.4482, val_loss: 2.9909, lr: 0.003000, 21.93s\n",
      "2021-12-03 15:50:00,392 - INFO - epoch complete!\n",
      "2021-12-03 15:50:00,395 - INFO - evaluating now!\n",
      "2021-12-03 15:50:01,777 - INFO - Epoch [85/100] train_loss: 2.4433, val_loss: 2.9841, lr: 0.003000, 21.77s\n",
      "2021-12-03 15:50:22,739 - INFO - epoch complete!\n",
      "2021-12-03 15:50:22,742 - INFO - evaluating now!\n",
      "2021-12-03 15:50:24,140 - INFO - Epoch [86/100] train_loss: 2.4449, val_loss: 3.0116, lr: 0.003000, 22.36s\n",
      "2021-12-03 15:50:44,026 - INFO - epoch complete!\n",
      "2021-12-03 15:50:44,029 - INFO - evaluating now!\n",
      "2021-12-03 15:50:45,429 - INFO - Epoch [87/100] train_loss: 2.4405, val_loss: 2.9805, lr: 0.003000, 21.29s\n",
      "2021-12-03 15:51:05,471 - INFO - epoch complete!\n",
      "2021-12-03 15:51:05,478 - INFO - evaluating now!\n",
      "2021-12-03 15:51:06,787 - INFO - Epoch [88/100] train_loss: 2.4406, val_loss: 3.0109, lr: 0.003000, 21.36s\n",
      "2021-12-03 15:51:25,310 - INFO - epoch complete!\n",
      "2021-12-03 15:51:25,313 - INFO - evaluating now!\n",
      "2021-12-03 15:51:26,604 - INFO - Epoch [89/100] train_loss: 2.4404, val_loss: 2.9874, lr: 0.003000, 19.81s\n",
      "2021-12-03 15:51:48,414 - INFO - epoch complete!\n",
      "2021-12-03 15:51:48,417 - INFO - evaluating now!\n",
      "2021-12-03 15:51:49,790 - INFO - Epoch [90/100] train_loss: 2.4369, val_loss: 2.9938, lr: 0.003000, 23.18s\n",
      "2021-12-03 15:52:09,647 - INFO - epoch complete!\n",
      "2021-12-03 15:52:09,650 - INFO - evaluating now!\n",
      "2021-12-03 15:52:11,037 - INFO - Epoch [91/100] train_loss: 2.4363, val_loss: 2.9933, lr: 0.003000, 21.24s\n",
      "2021-12-03 15:52:31,360 - INFO - epoch complete!\n",
      "2021-12-03 15:52:31,363 - INFO - evaluating now!\n",
      "2021-12-03 15:52:32,716 - INFO - Epoch [92/100] train_loss: 2.4325, val_loss: 3.0215, lr: 0.003000, 21.68s\n",
      "2021-12-03 15:52:52,008 - INFO - epoch complete!\n",
      "2021-12-03 15:52:52,011 - INFO - evaluating now!\n",
      "2021-12-03 15:52:53,406 - INFO - Epoch [93/100] train_loss: 2.4322, val_loss: 3.0056, lr: 0.003000, 20.69s\n",
      "2021-12-03 15:53:15,375 - INFO - epoch complete!\n",
      "2021-12-03 15:53:15,378 - INFO - evaluating now!\n",
      "2021-12-03 15:53:16,780 - INFO - Epoch [94/100] train_loss: 2.4313, val_loss: 3.0102, lr: 0.003000, 23.37s\n",
      "2021-12-03 15:53:37,117 - INFO - epoch complete!\n",
      "2021-12-03 15:53:37,120 - INFO - evaluating now!\n",
      "2021-12-03 15:53:38,494 - INFO - Epoch [95/100] train_loss: 2.4293, val_loss: 3.0138, lr: 0.003000, 21.71s\n",
      "2021-12-03 15:53:58,675 - INFO - epoch complete!\n",
      "2021-12-03 15:53:58,677 - INFO - evaluating now!\n",
      "2021-12-03 15:54:00,247 - INFO - Epoch [96/100] train_loss: 2.4295, val_loss: 3.0275, lr: 0.003000, 21.75s\n",
      "2021-12-03 15:54:20,971 - INFO - epoch complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-03 15:54:20,974 - INFO - evaluating now!\n",
      "2021-12-03 15:54:22,361 - INFO - Epoch [97/100] train_loss: 2.4270, val_loss: 3.0077, lr: 0.003000, 22.11s\n",
      "2021-12-03 15:54:42,798 - INFO - epoch complete!\n",
      "2021-12-03 15:54:42,801 - INFO - evaluating now!\n",
      "2021-12-03 15:54:44,187 - INFO - Epoch [98/100] train_loss: 2.4265, val_loss: 2.9997, lr: 0.003000, 21.82s\n",
      "2021-12-03 15:55:04,196 - INFO - epoch complete!\n",
      "2021-12-03 15:55:04,198 - INFO - evaluating now!\n",
      "2021-12-03 15:55:05,531 - INFO - Epoch [99/100] train_loss: 2.4255, val_loss: 3.0201, lr: 0.003000, 21.34s\n",
      "2021-12-03 15:55:05,534 - INFO - Trained totally 100 epochs, average train time is 21.300s, average eval time is 1.387s\n",
      "2021-12-03 15:55:05,553 - INFO - Loaded model at 18\n",
      "2021-12-03 15:55:05,555 - INFO - Saved model at ./libcity/cache/model_cache/AGCRN_METR_LA.m\n",
      "2021-12-03 15:55:05,570 - INFO - Loaded model at ./libcity/cache/model_cache/AGCRN_METR_LA.m\n",
      "2021-12-03 15:55:05,577 - INFO - Start evaluating ...\n",
      "2021-12-03 15:55:15,363 - INFO - Note that you select the single mode to evaluate!\n",
      "2021-12-03 15:55:15,366 - INFO - Evaluate result is {\"MAE@1\": 9.186357498168945, \"MAPE@1\": Infinity, \"MSE@1\": 452.9798889160156, \"RMSE@1\": 21.283323287963867, \"masked_MAE@1\": 2.3711440563201904, \"masked_MSE@1\": 17.553159713745117, \"masked_RMSE@1\": 4.1896491050720215, \"masked_MAPE@1\": 0.05905641242861748, \"R2@1\": 0.12644011480194894, \"EVAR@1\": 0.23216331005096436, \"MAE@2\": 9.507854461669922, \"MAPE@2\": Infinity, \"MSE@2\": 468.3049621582031, \"RMSE@2\": 21.64035415649414, \"masked_MAE@2\": 2.6299099922180176, \"masked_MSE@2\": 24.420654296875, \"masked_RMSE@2\": 4.941725730895996, \"masked_MAPE@2\": 0.06767839193344116, \"R2@2\": 0.09690917490201778, \"EVAR@2\": 0.20781725645065308, \"MAE@3\": 9.707433700561523, \"MAPE@3\": Infinity, \"MSE@3\": 475.0004577636719, \"RMSE@3\": 21.794506072998047, \"masked_MAE@3\": 2.8141839504241943, \"masked_MSE@3\": 29.37421226501465, \"masked_RMSE@3\": 5.419798374176025, \"masked_MAPE@3\": 0.07450777292251587, \"R2@3\": 0.08402003452047402, \"EVAR@3\": 0.19760698080062866, \"MAE@4\": 9.862526893615723, \"MAPE@4\": Infinity, \"MSE@4\": 480.4172668457031, \"RMSE@4\": 21.91842269897461, \"masked_MAE@4\": 2.9619407653808594, \"masked_MSE@4\": 33.82002639770508, \"masked_RMSE@4\": 5.8154988288879395, \"masked_MAPE@4\": 0.08004960417747498, \"R2@4\": 0.07360483531187478, \"EVAR@4\": 0.1898183822631836, \"MAE@5\": 9.98029613494873, \"MAPE@5\": Infinity, \"MSE@5\": 485.0303955078125, \"RMSE@5\": 22.023405075073242, \"masked_MAE@5\": 3.0727477073669434, \"masked_MSE@5\": 37.67275619506836, \"masked_RMSE@5\": 6.137813568115234, \"masked_MAPE@5\": 0.0848245769739151, \"R2@5\": 0.06473670118343677, \"EVAR@5\": 0.18201887607574463, \"MAE@6\": 10.071779251098633, \"MAPE@6\": Infinity, \"MSE@6\": 488.46783447265625, \"RMSE@6\": 22.101308822631836, \"masked_MAE@6\": 3.1659116744995117, \"masked_MSE@6\": 40.85795593261719, \"masked_RMSE@6\": 6.392022609710693, \"masked_MAPE@6\": 0.08801522105932236, \"R2@6\": 0.05812856534867483, \"EVAR@6\": 0.17569011449813843, \"MAE@7\": 10.14780044555664, \"MAPE@7\": Infinity, \"MSE@7\": 491.265380859375, \"RMSE@7\": 22.164506912231445, \"masked_MAE@7\": 3.2447938919067383, \"masked_MSE@7\": 43.598018646240234, \"masked_RMSE@7\": 6.602879524230957, \"masked_MAPE@7\": 0.09082777053117752, \"R2@7\": 0.05276170018276671, \"EVAR@7\": 0.17271286249160767, \"MAE@8\": 10.23678970336914, \"MAPE@8\": Infinity, \"MSE@8\": 495.1107482910156, \"RMSE@8\": 22.251083374023438, \"masked_MAE@8\": 3.3242008686065674, \"masked_MSE@8\": 45.979400634765625, \"masked_RMSE@8\": 6.780811309814453, \"masked_MAPE@8\": 0.09379281103610992, \"R2@8\": 0.045374269866757855, \"EVAR@8\": 0.16709232330322266, \"MAE@9\": 10.315547943115234, \"MAPE@9\": Infinity, \"MSE@9\": 498.9259948730469, \"RMSE@9\": 22.336650848388672, \"masked_MAE@9\": 3.3956196308135986, \"masked_MSE@9\": 48.645606994628906, \"masked_RMSE@9\": 6.974640369415283, \"masked_MAPE@9\": 0.09616658091545105, \"R2@9\": 0.03804449655969533, \"EVAR@9\": 0.16061687469482422, \"MAE@10\": 10.357146263122559, \"MAPE@10\": Infinity, \"MSE@10\": 498.7630310058594, \"RMSE@10\": 22.333003997802734, \"masked_MAE@10\": 3.460343837738037, \"masked_MSE@10\": 51.14466857910156, \"masked_RMSE@10\": 7.15155029296875, \"masked_MAPE@10\": 0.0984298512339592, \"R2@10\": 0.038390384870213734, \"EVAR@10\": 0.1610811948776245, \"MAE@11\": 10.409284591674805, \"MAPE@11\": Infinity, \"MSE@11\": 499.7064208984375, \"RMSE@11\": 22.354114532470703, \"masked_MAE@11\": 3.5263049602508545, \"masked_MSE@11\": 53.44047927856445, \"masked_RMSE@11\": 7.310299396514893, \"masked_MAPE@11\": 0.1006389707326889, \"R2@11\": 0.03660188680507925, \"EVAR@11\": 0.1590939164161682, \"MAE@12\": 10.489607810974121, \"MAPE@12\": Infinity, \"MSE@12\": 503.3408203125, \"RMSE@12\": 22.435258865356445, \"masked_MAE@12\": 3.6040358543395996, \"masked_MSE@12\": 56.12724685668945, \"masked_RMSE@12\": 7.491811752319336, \"masked_MAPE@12\": 0.10321549326181412, \"R2@12\": 0.029623258929190044, \"EVAR@12\": 0.15327131748199463}\n",
      "2021-12-03 15:55:15,368 - INFO - Evaluate result is saved at ./libcity/cache/evaluate_cache/2021_12_03_15_55_15_AGCRN_METR_LA.json\n",
      "2021-12-03 15:55:15,382 - INFO - Evaluate result is saved at ./libcity/cache/evaluate_cache/2021_12_03_15_55_15_AGCRN_METR_LA.csv\n",
      "2021-12-03 15:55:15,409 - INFO - \n",
      "          MAE  MAPE         MSE       RMSE  masked_MAE  masked_MSE  \\\n",
      "1    9.186357   inf  452.979889  21.283323    2.371144   17.553160   \n",
      "2    9.507854   inf  468.304962  21.640354    2.629910   24.420654   \n",
      "3    9.707434   inf  475.000458  21.794506    2.814184   29.374212   \n",
      "4    9.862527   inf  480.417267  21.918423    2.961941   33.820026   \n",
      "5    9.980296   inf  485.030396  22.023405    3.072748   37.672756   \n",
      "6   10.071779   inf  488.467834  22.101309    3.165912   40.857956   \n",
      "7   10.147800   inf  491.265381  22.164507    3.244794   43.598019   \n",
      "8   10.236790   inf  495.110748  22.251083    3.324201   45.979401   \n",
      "9   10.315548   inf  498.925995  22.336651    3.395620   48.645607   \n",
      "10  10.357146   inf  498.763031  22.333004    3.460344   51.144669   \n",
      "11  10.409285   inf  499.706421  22.354115    3.526305   53.440479   \n",
      "12  10.489608   inf  503.340820  22.435259    3.604036   56.127247   \n",
      "\n",
      "    masked_RMSE  masked_MAPE        R2      EVAR  \n",
      "1      4.189649     0.059056  0.126440  0.232163  \n",
      "2      4.941726     0.067678  0.096909  0.207817  \n",
      "3      5.419798     0.074508  0.084020  0.197607  \n",
      "4      5.815499     0.080050  0.073605  0.189818  \n",
      "5      6.137814     0.084825  0.064737  0.182019  \n",
      "6      6.392023     0.088015  0.058129  0.175690  \n",
      "7      6.602880     0.090828  0.052762  0.172713  \n",
      "8      6.780811     0.093793  0.045374  0.167092  \n",
      "9      6.974640     0.096167  0.038044  0.160617  \n",
      "10     7.151550     0.098430  0.038390  0.161081  \n",
      "11     7.310299     0.100639  0.036602  0.159094  \n",
      "12     7.491812     0.103215  0.029623  0.153271  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>masked_MAE</th>\n",
       "      <th>masked_MSE</th>\n",
       "      <th>masked_RMSE</th>\n",
       "      <th>masked_MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>EVAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.186357</td>\n",
       "      <td>inf</td>\n",
       "      <td>452.979889</td>\n",
       "      <td>21.283323</td>\n",
       "      <td>2.371144</td>\n",
       "      <td>17.553160</td>\n",
       "      <td>4.189649</td>\n",
       "      <td>0.059056</td>\n",
       "      <td>0.126440</td>\n",
       "      <td>0.232163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.507854</td>\n",
       "      <td>inf</td>\n",
       "      <td>468.304962</td>\n",
       "      <td>21.640354</td>\n",
       "      <td>2.629910</td>\n",
       "      <td>24.420654</td>\n",
       "      <td>4.941726</td>\n",
       "      <td>0.067678</td>\n",
       "      <td>0.096909</td>\n",
       "      <td>0.207817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.707434</td>\n",
       "      <td>inf</td>\n",
       "      <td>475.000458</td>\n",
       "      <td>21.794506</td>\n",
       "      <td>2.814184</td>\n",
       "      <td>29.374212</td>\n",
       "      <td>5.419798</td>\n",
       "      <td>0.074508</td>\n",
       "      <td>0.084020</td>\n",
       "      <td>0.197607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.862527</td>\n",
       "      <td>inf</td>\n",
       "      <td>480.417267</td>\n",
       "      <td>21.918423</td>\n",
       "      <td>2.961941</td>\n",
       "      <td>33.820026</td>\n",
       "      <td>5.815499</td>\n",
       "      <td>0.080050</td>\n",
       "      <td>0.073605</td>\n",
       "      <td>0.189818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.980296</td>\n",
       "      <td>inf</td>\n",
       "      <td>485.030396</td>\n",
       "      <td>22.023405</td>\n",
       "      <td>3.072748</td>\n",
       "      <td>37.672756</td>\n",
       "      <td>6.137814</td>\n",
       "      <td>0.084825</td>\n",
       "      <td>0.064737</td>\n",
       "      <td>0.182019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.071779</td>\n",
       "      <td>inf</td>\n",
       "      <td>488.467834</td>\n",
       "      <td>22.101309</td>\n",
       "      <td>3.165912</td>\n",
       "      <td>40.857956</td>\n",
       "      <td>6.392023</td>\n",
       "      <td>0.088015</td>\n",
       "      <td>0.058129</td>\n",
       "      <td>0.175690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.147800</td>\n",
       "      <td>inf</td>\n",
       "      <td>491.265381</td>\n",
       "      <td>22.164507</td>\n",
       "      <td>3.244794</td>\n",
       "      <td>43.598019</td>\n",
       "      <td>6.602880</td>\n",
       "      <td>0.090828</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>0.172713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.236790</td>\n",
       "      <td>inf</td>\n",
       "      <td>495.110748</td>\n",
       "      <td>22.251083</td>\n",
       "      <td>3.324201</td>\n",
       "      <td>45.979401</td>\n",
       "      <td>6.780811</td>\n",
       "      <td>0.093793</td>\n",
       "      <td>0.045374</td>\n",
       "      <td>0.167092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.315548</td>\n",
       "      <td>inf</td>\n",
       "      <td>498.925995</td>\n",
       "      <td>22.336651</td>\n",
       "      <td>3.395620</td>\n",
       "      <td>48.645607</td>\n",
       "      <td>6.974640</td>\n",
       "      <td>0.096167</td>\n",
       "      <td>0.038044</td>\n",
       "      <td>0.160617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.357146</td>\n",
       "      <td>inf</td>\n",
       "      <td>498.763031</td>\n",
       "      <td>22.333004</td>\n",
       "      <td>3.460344</td>\n",
       "      <td>51.144669</td>\n",
       "      <td>7.151550</td>\n",
       "      <td>0.098430</td>\n",
       "      <td>0.038390</td>\n",
       "      <td>0.161081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.409285</td>\n",
       "      <td>inf</td>\n",
       "      <td>499.706421</td>\n",
       "      <td>22.354115</td>\n",
       "      <td>3.526305</td>\n",
       "      <td>53.440479</td>\n",
       "      <td>7.310299</td>\n",
       "      <td>0.100639</td>\n",
       "      <td>0.036602</td>\n",
       "      <td>0.159094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.489608</td>\n",
       "      <td>inf</td>\n",
       "      <td>503.340820</td>\n",
       "      <td>22.435259</td>\n",
       "      <td>3.604036</td>\n",
       "      <td>56.127247</td>\n",
       "      <td>7.491812</td>\n",
       "      <td>0.103215</td>\n",
       "      <td>0.029623</td>\n",
       "      <td>0.153271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MAE  MAPE         MSE       RMSE  masked_MAE  masked_MSE  \\\n",
       "1    9.186357   inf  452.979889  21.283323    2.371144   17.553160   \n",
       "2    9.507854   inf  468.304962  21.640354    2.629910   24.420654   \n",
       "3    9.707434   inf  475.000458  21.794506    2.814184   29.374212   \n",
       "4    9.862527   inf  480.417267  21.918423    2.961941   33.820026   \n",
       "5    9.980296   inf  485.030396  22.023405    3.072748   37.672756   \n",
       "6   10.071779   inf  488.467834  22.101309    3.165912   40.857956   \n",
       "7   10.147800   inf  491.265381  22.164507    3.244794   43.598019   \n",
       "8   10.236790   inf  495.110748  22.251083    3.324201   45.979401   \n",
       "9   10.315548   inf  498.925995  22.336651    3.395620   48.645607   \n",
       "10  10.357146   inf  498.763031  22.333004    3.460344   51.144669   \n",
       "11  10.409285   inf  499.706421  22.354115    3.526305   53.440479   \n",
       "12  10.489608   inf  503.340820  22.435259    3.604036   56.127247   \n",
       "\n",
       "    masked_RMSE  masked_MAPE        R2      EVAR  \n",
       "1      4.189649     0.059056  0.126440  0.232163  \n",
       "2      4.941726     0.067678  0.096909  0.207817  \n",
       "3      5.419798     0.074508  0.084020  0.197607  \n",
       "4      5.815499     0.080050  0.073605  0.189818  \n",
       "5      6.137814     0.084825  0.064737  0.182019  \n",
       "6      6.392023     0.088015  0.058129  0.175690  \n",
       "7      6.602880     0.090828  0.052762  0.172713  \n",
       "8      6.780811     0.093793  0.045374  0.167092  \n",
       "9      6.974640     0.096167  0.038044  0.160617  \n",
       "10     7.151550     0.098430  0.038390  0.161081  \n",
       "11     7.310299     0.100639  0.036602  0.159094  \n",
       "12     7.491812     0.103215  0.029623  0.153271  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test AGCRNCELL\n",
    "from libcity.data import get_dataset\n",
    "from libcity.utils import get_executor\n",
    "from libcity.utils import get_model\n",
    "from libcity.utils import get_logger\n",
    "\n",
    "\n",
    "config = {\n",
    "    'log_level': 'INFO',\n",
    "\n",
    "    'dataset': 'METR_LA',\n",
    "    'model': 'AGCRN',\n",
    "    'evaluator': 'TrafficStateEvaluator',\n",
    "    'executor': 'TrafficStateExecutor',\n",
    "    'dataset_class': 'TrafficStatePointDataset',\n",
    "    'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MSE', 'masked_RMSE', 'masked_MAPE', 'R2', 'EVAR'],\n",
    "    'weight_col': 'cost',\n",
    "    'data_col': ['traffic_speed'],\n",
    "    'calculate_weight': True,\n",
    "    'adj_epsilon': 0.1,\n",
    "    'add_time_in_day': False,\n",
    "    'add_day_in_week': False,\n",
    "    'pad_with_last_sample': False,\n",
    "    'scaler': \"standard\",\n",
    "\n",
    "    'num_workers': 1,\n",
    "    'cache_dataset': True,\n",
    "    'gpu': True,\n",
    "    'gpu_id': '1',\n",
    "    'batch_size': 64,\n",
    "\n",
    "    'input_window': 12,\n",
    "    'output_window': 12,\n",
    "    'tod': False,\n",
    "    'column_wise': False,\n",
    "    'default_graph': True,\n",
    "    'embed_dim': 10,\n",
    "    'rnn_units': 64,\n",
    "    'num_layers': 2,\n",
    "    'cheb_order': 2,\n",
    "\n",
    "    'train_rate': 0.7,\n",
    "    'eval_rate': 0.1,\n",
    "    'learning_rate': 0.003,\n",
    "    'learner': 'adam',\n",
    "    'lr_decay': False,\n",
    "    'lr_decay_rate': 0.3,\n",
    "    'steps': [5, 20, 40, 70],\n",
    "    'lr_scheduler': 'multisteplr',\n",
    "    'epoch': 0,\n",
    "    'max_epoch': 100,\n",
    "    'clip_grad_norm': False,\n",
    "    'use_early_stop': False,\n",
    "    'max_grad_norm': 5,\n",
    "    'patience': 15,\n",
    "}\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config['gpu_id']\n",
    "import torch\n",
    "config['device'] = torch.device(\"cuda\" if torch.cuda.is_available() and config['gpu'] else \"cpu\")\n",
    "config['task']='traffic_state_pred'\n",
    "\n",
    "logger = get_logger(config)\n",
    "# 加载数据集\n",
    "dataset = get_dataset(config)\n",
    "# 转换数据，并划分数据集\n",
    "train_data, valid_data, test_data = dataset.get_data()\n",
    "print(len(train_data), len(train_data.dataset), train_data.dataset[0][0].shape, train_data.dataset[0][1].shape, train_data.batch_size)\n",
    "print(len(valid_data), len(valid_data.dataset), valid_data.dataset[0][0].shape, valid_data.dataset[0][1].shape, valid_data.batch_size)\n",
    "print(len(test_data), len(test_data.dataset), test_data.dataset[0][0].shape, test_data.dataset[0][1].shape, test_data.batch_size)\n",
    "\n",
    "data_feature = dataset.get_data_feature()\n",
    "print(data_feature['adj_mx'].shape)\n",
    "print(data_feature['adj_mx'].sum())\n",
    "\n",
    "model = AGCRN(config,data_feature)\n",
    "\n",
    "# 加载执行器\n",
    "model_cache_file = './libcity/cache/model_cache/' + config['model'] + '_' + config['dataset'] + '.m'\n",
    "executor = get_executor(config, model)\n",
    "# 训练\n",
    "executor.train(train_data, valid_data)\n",
    "executor.save_model(model_cache_file)\n",
    "executor.load_model(model_cache_file)\n",
    "# 评估，评估结果将会放在 cache/evaluate_cache 下\n",
    "executor.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519679b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGCN(AbstractTrafficStateModel):\n",
    "    def __init__(self, config, data_feature):\n",
    "        self.num_nodes = data_feature.get('num_nodes', 1)\n",
    "        self.feature_dim = data_feature.get('feature_dim', 1)\n",
    "        config['num_nodes'] = self.num_nodes\n",
    "        config['feature_dim'] = self.feature_dim\n",
    "\n",
    "        super().__init__(config, data_feature)\n",
    "        self.input_window = config.get('input_window', 1)\n",
    "        self.output_window = config.get('output_window', 1)\n",
    "        self.output_dim = self.data_feature.get('output_dim', 1)\n",
    "        self.hidden_dim = config.get('rnn_units', 64)\n",
    "        self.embed_dim = config.get('embed_dim', 10)\n",
    "\n",
    "#         self.gcn=GNN.AVWGCN(self.feature_dim,self.hidden_dim,config.get('cheb_order', 2),self.num_nodes,self.embed_dim)\n",
    "#         self.gcn_encode=GNN.TimedistributedGCN(self.gcn)\n",
    "        self.trnn=RNN.TemporalGRU(config,0,0)\n",
    "        \n",
    "        self.end_conv = nn.Conv2d(1, self.output_window * self.output_dim, kernel_size=(1, self.hidden_dim), bias=True)\n",
    "\n",
    "        self.device = config.get('device', torch.device('cpu'))\n",
    "        self._logger = getLogger()\n",
    "        self._scaler = self.data_feature.get('scaler')\n",
    "        self._init_parameters()\n",
    "    \n",
    "    def _init_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "            else:\n",
    "                nn.init.uniform_(p)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # source: B, T_1, N, D\n",
    "        # target: B, T_2, N, D\n",
    "        source = batch['X']\n",
    "        \n",
    "        batch_size=source.shape[0]\n",
    "                \n",
    "        output = self.trnn(source)  # B, T, N, hidden\n",
    "        output = output[:, -1:, :, :]                                       # B, 1, N, hidden\n",
    "\n",
    "        # CNN based predictor\n",
    "        output = self.end_conv(output)                           # B, T*C, N, 1\n",
    "        output = output.squeeze(-1).reshape(-1, self.output_window, self.output_dim, self.num_nodes)\n",
    "        output = output.permute(0, 1, 3, 2)                      # B, T, N, C\n",
    "        return output\n",
    "    \n",
    "    def calculate_loss(self, batch):\n",
    "        y_true = batch['y']\n",
    "        y_predicted = self.predict(batch)\n",
    "        y_true = self._scaler.inverse_transform(y_true[..., :self.output_dim])\n",
    "        y_predicted = self._scaler.inverse_transform(y_predicted[..., :self.output_dim])\n",
    "        return loss.masked_mae_torch(y_predicted, y_true, 0)\n",
    "\n",
    "    def predict(self, batch):\n",
    "        return self.forward(batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c81b2ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:20:12,017 - INFO - Loaded file METR_LA.geo, num_nodes=207\n",
      "2021-12-02 17:20:12,017 - INFO - Loaded file METR_LA.geo, num_nodes=207\n",
      "2021-12-02 17:20:12,017 - INFO - Loaded file METR_LA.geo, num_nodes=207\n",
      "2021-12-02 17:20:12,027 - INFO - set_weight_link_or_dist: dist\n",
      "2021-12-02 17:20:12,027 - INFO - set_weight_link_or_dist: dist\n",
      "2021-12-02 17:20:12,027 - INFO - set_weight_link_or_dist: dist\n",
      "2021-12-02 17:20:12,029 - INFO - init_weight_inf_or_zero: inf\n",
      "2021-12-02 17:20:12,029 - INFO - init_weight_inf_or_zero: inf\n",
      "2021-12-02 17:20:12,029 - INFO - init_weight_inf_or_zero: inf\n",
      "2021-12-02 17:20:12,067 - INFO - Loaded file METR_LA.rel, shape=(207, 207)\n",
      "2021-12-02 17:20:12,067 - INFO - Loaded file METR_LA.rel, shape=(207, 207)\n",
      "2021-12-02 17:20:12,067 - INFO - Loaded file METR_LA.rel, shape=(207, 207)\n",
      "2021-12-02 17:20:12,070 - INFO - Loading ./libcity/cache/dataset_cache/point_based_METR_LA_12_12_0.7_0.1_standard_64_False_False_False_False.npz\n",
      "2021-12-02 17:20:12,070 - INFO - Loading ./libcity/cache/dataset_cache/point_based_METR_LA_12_12_0.7_0.1_standard_64_False_False_False_False.npz\n",
      "2021-12-02 17:20:12,070 - INFO - Loading ./libcity/cache/dataset_cache/point_based_METR_LA_12_12_0.7_0.1_standard_64_False_False_False_False.npz\n",
      "2021-12-02 17:20:15,270 - INFO - train\tx: (23974, 12, 207, 1), y: (23974, 12, 207, 1)\n",
      "2021-12-02 17:20:15,270 - INFO - train\tx: (23974, 12, 207, 1), y: (23974, 12, 207, 1)\n",
      "2021-12-02 17:20:15,270 - INFO - train\tx: (23974, 12, 207, 1), y: (23974, 12, 207, 1)\n",
      "2021-12-02 17:20:15,276 - INFO - eval\tx: (3425, 12, 207, 1), y: (3425, 12, 207, 1)\n",
      "2021-12-02 17:20:15,276 - INFO - eval\tx: (3425, 12, 207, 1), y: (3425, 12, 207, 1)\n",
      "2021-12-02 17:20:15,276 - INFO - eval\tx: (3425, 12, 207, 1), y: (3425, 12, 207, 1)\n",
      "2021-12-02 17:20:15,278 - INFO - test\tx: (6850, 12, 207, 1), y: (6850, 12, 207, 1)\n",
      "2021-12-02 17:20:15,278 - INFO - test\tx: (6850, 12, 207, 1), y: (6850, 12, 207, 1)\n",
      "2021-12-02 17:20:15,278 - INFO - test\tx: (6850, 12, 207, 1), y: (6850, 12, 207, 1)\n",
      "2021-12-02 17:20:15,625 - INFO - StandardScaler mean: 54.40592829587626, std: 19.493739270573098\n",
      "2021-12-02 17:20:15,625 - INFO - StandardScaler mean: 54.40592829587626, std: 19.493739270573098\n",
      "2021-12-02 17:20:15,625 - INFO - StandardScaler mean: 54.40592829587626, std: 19.493739270573098\n",
      "2021-12-02 17:20:15,629 - INFO - NoneScaler\n",
      "2021-12-02 17:20:15,629 - INFO - NoneScaler\n",
      "2021-12-02 17:20:15,629 - INFO - NoneScaler\n",
      "375 23974 (12, 207, 1) (12, 207, 1) 64\n",
      "54 3425 (12, 207, 1) (12, 207, 1) 64\n",
      "108 6850 (12, 207, 1) (12, 207, 1) 64\n",
      "(207, 207)\n",
      "inf\n",
      "2021-12-02 17:20:16,591 - INFO - AGCRN(\n",
      "  (encoder): AVWDCRNN(\n",
      "    (dcrnn_cells): ModuleList(\n",
      "      (0): AGCRNCell(\n",
      "        (gate): AVWGCN()\n",
      "        (update): AVWGCN()\n",
      "      )\n",
      "      (1): AGCRNCell(\n",
      "        (gate): AVWGCN()\n",
      "        (update): AVWGCN()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (end_conv): Conv2d(1, 12, kernel_size=(1, 64), stride=(1, 1))\n",
      ")\n",
      "2021-12-02 17:20:16,591 - INFO - AGCRN(\n",
      "  (encoder): AVWDCRNN(\n",
      "    (dcrnn_cells): ModuleList(\n",
      "      (0): AGCRNCell(\n",
      "        (gate): AVWGCN()\n",
      "        (update): AVWGCN()\n",
      "      )\n",
      "      (1): AGCRNCell(\n",
      "        (gate): AVWGCN()\n",
      "        (update): AVWGCN()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (end_conv): Conv2d(1, 12, kernel_size=(1, 64), stride=(1, 1))\n",
      ")\n",
      "2021-12-02 17:20:16,591 - INFO - AGCRN(\n",
      "  (encoder): AVWDCRNN(\n",
      "    (dcrnn_cells): ModuleList(\n",
      "      (0): AGCRNCell(\n",
      "        (gate): AVWGCN()\n",
      "        (update): AVWGCN()\n",
      "      )\n",
      "      (1): AGCRNCell(\n",
      "        (gate): AVWGCN()\n",
      "        (update): AVWGCN()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (end_conv): Conv2d(1, 12, kernel_size=(1, 64), stride=(1, 1))\n",
      ")\n",
      "2021-12-02 17:20:16,595 - INFO - node_embeddings\ttorch.Size([207, 10])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,595 - INFO - node_embeddings\ttorch.Size([207, 10])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,595 - INFO - node_embeddings\ttorch.Size([207, 10])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,597 - INFO - encoder.dcrnn_cells.0.gate.weights_pool\ttorch.Size([10, 2, 65, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,597 - INFO - encoder.dcrnn_cells.0.gate.weights_pool\ttorch.Size([10, 2, 65, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,597 - INFO - encoder.dcrnn_cells.0.gate.weights_pool\ttorch.Size([10, 2, 65, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,601 - INFO - encoder.dcrnn_cells.0.gate.bias_pool\ttorch.Size([10, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,601 - INFO - encoder.dcrnn_cells.0.gate.bias_pool\ttorch.Size([10, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,601 - INFO - encoder.dcrnn_cells.0.gate.bias_pool\ttorch.Size([10, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,603 - INFO - encoder.dcrnn_cells.0.update.weights_pool\ttorch.Size([10, 2, 65, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,603 - INFO - encoder.dcrnn_cells.0.update.weights_pool\ttorch.Size([10, 2, 65, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,603 - INFO - encoder.dcrnn_cells.0.update.weights_pool\ttorch.Size([10, 2, 65, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,605 - INFO - encoder.dcrnn_cells.0.update.bias_pool\ttorch.Size([10, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,605 - INFO - encoder.dcrnn_cells.0.update.bias_pool\ttorch.Size([10, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,605 - INFO - encoder.dcrnn_cells.0.update.bias_pool\ttorch.Size([10, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,607 - INFO - encoder.dcrnn_cells.1.gate.weights_pool\ttorch.Size([10, 2, 128, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,607 - INFO - encoder.dcrnn_cells.1.gate.weights_pool\ttorch.Size([10, 2, 128, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,607 - INFO - encoder.dcrnn_cells.1.gate.weights_pool\ttorch.Size([10, 2, 128, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,609 - INFO - encoder.dcrnn_cells.1.gate.bias_pool\ttorch.Size([10, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,609 - INFO - encoder.dcrnn_cells.1.gate.bias_pool\ttorch.Size([10, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,609 - INFO - encoder.dcrnn_cells.1.gate.bias_pool\ttorch.Size([10, 128])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,614 - INFO - encoder.dcrnn_cells.1.update.weights_pool\ttorch.Size([10, 2, 128, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,614 - INFO - encoder.dcrnn_cells.1.update.weights_pool\ttorch.Size([10, 2, 128, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,614 - INFO - encoder.dcrnn_cells.1.update.weights_pool\ttorch.Size([10, 2, 128, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,616 - INFO - encoder.dcrnn_cells.1.update.bias_pool\ttorch.Size([10, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,616 - INFO - encoder.dcrnn_cells.1.update.bias_pool\ttorch.Size([10, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,616 - INFO - encoder.dcrnn_cells.1.update.bias_pool\ttorch.Size([10, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,618 - INFO - end_conv.weight\ttorch.Size([12, 1, 1, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,618 - INFO - end_conv.weight\ttorch.Size([12, 1, 1, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,618 - INFO - end_conv.weight\ttorch.Size([12, 1, 1, 64])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,620 - INFO - end_conv.bias\ttorch.Size([12])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,620 - INFO - end_conv.bias\ttorch.Size([12])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,620 - INFO - end_conv.bias\ttorch.Size([12])\tcuda:0\tTrue\n",
      "2021-12-02 17:20:16,623 - INFO - Total parameter numbers: 747810\n",
      "2021-12-02 17:20:16,623 - INFO - Total parameter numbers: 747810\n",
      "2021-12-02 17:20:16,623 - INFO - Total parameter numbers: 747810\n",
      "2021-12-02 17:20:16,625 - INFO - You select `adam` optimizer.\n",
      "2021-12-02 17:20:16,625 - INFO - You select `adam` optimizer.\n",
      "2021-12-02 17:20:16,625 - INFO - You select `adam` optimizer.\n",
      "2021-12-02 17:20:16,628 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2021-12-02 17:20:16,628 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2021-12-02 17:20:16,628 - WARNING - Received none train loss func and will use the loss func defined in the model.\n",
      "2021-12-02 17:20:16,630 - INFO - Start training ...\n",
      "2021-12-02 17:20:16,630 - INFO - Start training ...\n",
      "2021-12-02 17:20:16,630 - INFO - Start training ...\n",
      "2021-12-02 17:20:16,632 - INFO - num_batches:375\n",
      "2021-12-02 17:20:16,632 - INFO - num_batches:375\n",
      "2021-12-02 17:20:16,632 - INFO - num_batches:375\n",
      "2021-12-02 17:20:58,792 - INFO - epoch complete!\n",
      "2021-12-02 17:20:58,792 - INFO - epoch complete!\n",
      "2021-12-02 17:20:58,792 - INFO - epoch complete!\n",
      "2021-12-02 17:20:58,797 - INFO - evaluating now!\n",
      "2021-12-02 17:20:58,797 - INFO - evaluating now!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:20:58,797 - INFO - evaluating now!\n",
      "2021-12-02 17:21:01,324 - INFO - Epoch [0/100] train_loss: 4.3200, val_loss: 3.4323, lr: 0.003000, 44.69s\n",
      "2021-12-02 17:21:01,324 - INFO - Epoch [0/100] train_loss: 4.3200, val_loss: 3.4323, lr: 0.003000, 44.69s\n",
      "2021-12-02 17:21:01,324 - INFO - Epoch [0/100] train_loss: 4.3200, val_loss: 3.4323, lr: 0.003000, 44.69s\n",
      "2021-12-02 17:21:01,372 - INFO - Saved model at 0\n",
      "2021-12-02 17:21:01,372 - INFO - Saved model at 0\n",
      "2021-12-02 17:21:01,372 - INFO - Saved model at 0\n",
      "2021-12-02 17:21:01,376 - INFO - Val loss decrease from inf to 3.4323, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch0.tar\n",
      "2021-12-02 17:21:01,376 - INFO - Val loss decrease from inf to 3.4323, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch0.tar\n",
      "2021-12-02 17:21:01,376 - INFO - Val loss decrease from inf to 3.4323, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch0.tar\n",
      "2021-12-02 17:21:40,438 - INFO - epoch complete!\n",
      "2021-12-02 17:21:40,438 - INFO - epoch complete!\n",
      "2021-12-02 17:21:40,438 - INFO - epoch complete!\n",
      "2021-12-02 17:21:40,443 - INFO - evaluating now!\n",
      "2021-12-02 17:21:40,443 - INFO - evaluating now!\n",
      "2021-12-02 17:21:40,443 - INFO - evaluating now!\n",
      "2021-12-02 17:21:42,888 - INFO - Epoch [1/100] train_loss: 3.4244, val_loss: 3.2271, lr: 0.003000, 41.51s\n",
      "2021-12-02 17:21:42,888 - INFO - Epoch [1/100] train_loss: 3.4244, val_loss: 3.2271, lr: 0.003000, 41.51s\n",
      "2021-12-02 17:21:42,888 - INFO - Epoch [1/100] train_loss: 3.4244, val_loss: 3.2271, lr: 0.003000, 41.51s\n",
      "2021-12-02 17:21:42,933 - INFO - Saved model at 1\n",
      "2021-12-02 17:21:42,933 - INFO - Saved model at 1\n",
      "2021-12-02 17:21:42,933 - INFO - Saved model at 1\n",
      "2021-12-02 17:21:42,935 - INFO - Val loss decrease from 3.4323 to 3.2271, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch1.tar\n",
      "2021-12-02 17:21:42,935 - INFO - Val loss decrease from 3.4323 to 3.2271, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch1.tar\n",
      "2021-12-02 17:21:42,935 - INFO - Val loss decrease from 3.4323 to 3.2271, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch1.tar\n",
      "2021-12-02 17:22:23,919 - INFO - epoch complete!\n",
      "2021-12-02 17:22:23,919 - INFO - epoch complete!\n",
      "2021-12-02 17:22:23,919 - INFO - epoch complete!\n",
      "2021-12-02 17:22:23,924 - INFO - evaluating now!\n",
      "2021-12-02 17:22:23,924 - INFO - evaluating now!\n",
      "2021-12-02 17:22:23,924 - INFO - evaluating now!\n",
      "2021-12-02 17:22:26,381 - INFO - Epoch [2/100] train_loss: 3.2330, val_loss: 3.0757, lr: 0.003000, 43.44s\n",
      "2021-12-02 17:22:26,381 - INFO - Epoch [2/100] train_loss: 3.2330, val_loss: 3.0757, lr: 0.003000, 43.44s\n",
      "2021-12-02 17:22:26,381 - INFO - Epoch [2/100] train_loss: 3.2330, val_loss: 3.0757, lr: 0.003000, 43.44s\n",
      "2021-12-02 17:22:26,430 - INFO - Saved model at 2\n",
      "2021-12-02 17:22:26,430 - INFO - Saved model at 2\n",
      "2021-12-02 17:22:26,430 - INFO - Saved model at 2\n",
      "2021-12-02 17:22:26,433 - INFO - Val loss decrease from 3.2271 to 3.0757, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch2.tar\n",
      "2021-12-02 17:22:26,433 - INFO - Val loss decrease from 3.2271 to 3.0757, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch2.tar\n",
      "2021-12-02 17:22:26,433 - INFO - Val loss decrease from 3.2271 to 3.0757, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch2.tar\n",
      "2021-12-02 17:23:08,142 - INFO - epoch complete!\n",
      "2021-12-02 17:23:08,142 - INFO - epoch complete!\n",
      "2021-12-02 17:23:08,142 - INFO - epoch complete!\n",
      "2021-12-02 17:23:08,147 - INFO - evaluating now!\n",
      "2021-12-02 17:23:08,147 - INFO - evaluating now!\n",
      "2021-12-02 17:23:08,147 - INFO - evaluating now!\n",
      "2021-12-02 17:23:10,767 - INFO - Epoch [3/100] train_loss: 3.1186, val_loss: 3.0805, lr: 0.003000, 44.33s\n",
      "2021-12-02 17:23:10,767 - INFO - Epoch [3/100] train_loss: 3.1186, val_loss: 3.0805, lr: 0.003000, 44.33s\n",
      "2021-12-02 17:23:10,767 - INFO - Epoch [3/100] train_loss: 3.1186, val_loss: 3.0805, lr: 0.003000, 44.33s\n",
      "2021-12-02 17:23:53,256 - INFO - epoch complete!\n",
      "2021-12-02 17:23:53,256 - INFO - epoch complete!\n",
      "2021-12-02 17:23:53,256 - INFO - epoch complete!\n",
      "2021-12-02 17:23:53,261 - INFO - evaluating now!\n",
      "2021-12-02 17:23:53,261 - INFO - evaluating now!\n",
      "2021-12-02 17:23:53,261 - INFO - evaluating now!\n",
      "2021-12-02 17:23:55,887 - INFO - Epoch [4/100] train_loss: 3.0572, val_loss: 3.0345, lr: 0.003000, 45.12s\n",
      "2021-12-02 17:23:55,887 - INFO - Epoch [4/100] train_loss: 3.0572, val_loss: 3.0345, lr: 0.003000, 45.12s\n",
      "2021-12-02 17:23:55,887 - INFO - Epoch [4/100] train_loss: 3.0572, val_loss: 3.0345, lr: 0.003000, 45.12s\n",
      "2021-12-02 17:23:55,935 - INFO - Saved model at 4\n",
      "2021-12-02 17:23:55,935 - INFO - Saved model at 4\n",
      "2021-12-02 17:23:55,935 - INFO - Saved model at 4\n",
      "2021-12-02 17:23:55,938 - INFO - Val loss decrease from 3.0757 to 3.0345, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch4.tar\n",
      "2021-12-02 17:23:55,938 - INFO - Val loss decrease from 3.0757 to 3.0345, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch4.tar\n",
      "2021-12-02 17:23:55,938 - INFO - Val loss decrease from 3.0757 to 3.0345, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch4.tar\n",
      "2021-12-02 17:24:35,640 - INFO - epoch complete!\n",
      "2021-12-02 17:24:35,640 - INFO - epoch complete!\n",
      "2021-12-02 17:24:35,640 - INFO - epoch complete!\n",
      "2021-12-02 17:24:35,645 - INFO - evaluating now!\n",
      "2021-12-02 17:24:35,645 - INFO - evaluating now!\n",
      "2021-12-02 17:24:35,645 - INFO - evaluating now!\n",
      "2021-12-02 17:24:38,248 - INFO - Epoch [5/100] train_loss: 3.0078, val_loss: 2.9536, lr: 0.003000, 42.31s\n",
      "2021-12-02 17:24:38,248 - INFO - Epoch [5/100] train_loss: 3.0078, val_loss: 2.9536, lr: 0.003000, 42.31s\n",
      "2021-12-02 17:24:38,248 - INFO - Epoch [5/100] train_loss: 3.0078, val_loss: 2.9536, lr: 0.003000, 42.31s\n",
      "2021-12-02 17:24:38,295 - INFO - Saved model at 5\n",
      "2021-12-02 17:24:38,295 - INFO - Saved model at 5\n",
      "2021-12-02 17:24:38,295 - INFO - Saved model at 5\n",
      "2021-12-02 17:24:38,298 - INFO - Val loss decrease from 3.0345 to 2.9536, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch5.tar\n",
      "2021-12-02 17:24:38,298 - INFO - Val loss decrease from 3.0345 to 2.9536, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch5.tar\n",
      "2021-12-02 17:24:38,298 - INFO - Val loss decrease from 3.0345 to 2.9536, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch5.tar\n",
      "2021-12-02 17:25:19,889 - INFO - epoch complete!\n",
      "2021-12-02 17:25:19,889 - INFO - epoch complete!\n",
      "2021-12-02 17:25:19,889 - INFO - epoch complete!\n",
      "2021-12-02 17:25:19,893 - INFO - evaluating now!\n",
      "2021-12-02 17:25:19,893 - INFO - evaluating now!\n",
      "2021-12-02 17:25:19,893 - INFO - evaluating now!\n",
      "2021-12-02 17:25:22,310 - INFO - Epoch [6/100] train_loss: 2.9703, val_loss: 2.9650, lr: 0.003000, 44.01s\n",
      "2021-12-02 17:25:22,310 - INFO - Epoch [6/100] train_loss: 2.9703, val_loss: 2.9650, lr: 0.003000, 44.01s\n",
      "2021-12-02 17:25:22,310 - INFO - Epoch [6/100] train_loss: 2.9703, val_loss: 2.9650, lr: 0.003000, 44.01s\n",
      "2021-12-02 17:26:03,310 - INFO - epoch complete!\n",
      "2021-12-02 17:26:03,310 - INFO - epoch complete!\n",
      "2021-12-02 17:26:03,310 - INFO - epoch complete!\n",
      "2021-12-02 17:26:03,313 - INFO - evaluating now!\n",
      "2021-12-02 17:26:03,313 - INFO - evaluating now!\n",
      "2021-12-02 17:26:03,313 - INFO - evaluating now!\n",
      "2021-12-02 17:26:05,912 - INFO - Epoch [7/100] train_loss: 2.9362, val_loss: 2.9700, lr: 0.003000, 43.60s\n",
      "2021-12-02 17:26:05,912 - INFO - Epoch [7/100] train_loss: 2.9362, val_loss: 2.9700, lr: 0.003000, 43.60s\n",
      "2021-12-02 17:26:05,912 - INFO - Epoch [7/100] train_loss: 2.9362, val_loss: 2.9700, lr: 0.003000, 43.60s\n",
      "2021-12-02 17:26:46,572 - INFO - epoch complete!\n",
      "2021-12-02 17:26:46,572 - INFO - epoch complete!\n",
      "2021-12-02 17:26:46,572 - INFO - epoch complete!\n",
      "2021-12-02 17:26:46,578 - INFO - evaluating now!\n",
      "2021-12-02 17:26:46,578 - INFO - evaluating now!\n",
      "2021-12-02 17:26:46,578 - INFO - evaluating now!\n",
      "2021-12-02 17:26:48,982 - INFO - Epoch [8/100] train_loss: 2.9065, val_loss: 2.9722, lr: 0.003000, 43.07s\n",
      "2021-12-02 17:26:48,982 - INFO - Epoch [8/100] train_loss: 2.9065, val_loss: 2.9722, lr: 0.003000, 43.07s\n",
      "2021-12-02 17:26:48,982 - INFO - Epoch [8/100] train_loss: 2.9065, val_loss: 2.9722, lr: 0.003000, 43.07s\n",
      "2021-12-02 17:27:29,974 - INFO - epoch complete!\n",
      "2021-12-02 17:27:29,974 - INFO - epoch complete!\n",
      "2021-12-02 17:27:29,974 - INFO - epoch complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:27:29,978 - INFO - evaluating now!\n",
      "2021-12-02 17:27:29,978 - INFO - evaluating now!\n",
      "2021-12-02 17:27:29,978 - INFO - evaluating now!\n",
      "2021-12-02 17:27:32,558 - INFO - Epoch [9/100] train_loss: 2.8764, val_loss: 2.9523, lr: 0.003000, 43.57s\n",
      "2021-12-02 17:27:32,558 - INFO - Epoch [9/100] train_loss: 2.8764, val_loss: 2.9523, lr: 0.003000, 43.57s\n",
      "2021-12-02 17:27:32,558 - INFO - Epoch [9/100] train_loss: 2.8764, val_loss: 2.9523, lr: 0.003000, 43.57s\n",
      "2021-12-02 17:27:32,601 - INFO - Saved model at 9\n",
      "2021-12-02 17:27:32,601 - INFO - Saved model at 9\n",
      "2021-12-02 17:27:32,601 - INFO - Saved model at 9\n",
      "2021-12-02 17:27:32,603 - INFO - Val loss decrease from 2.9536 to 2.9523, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch9.tar\n",
      "2021-12-02 17:27:32,603 - INFO - Val loss decrease from 2.9536 to 2.9523, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch9.tar\n",
      "2021-12-02 17:27:32,603 - INFO - Val loss decrease from 2.9536 to 2.9523, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch9.tar\n",
      "2021-12-02 17:28:13,728 - INFO - epoch complete!\n",
      "2021-12-02 17:28:13,728 - INFO - epoch complete!\n",
      "2021-12-02 17:28:13,728 - INFO - epoch complete!\n",
      "2021-12-02 17:28:13,731 - INFO - evaluating now!\n",
      "2021-12-02 17:28:13,731 - INFO - evaluating now!\n",
      "2021-12-02 17:28:13,731 - INFO - evaluating now!\n",
      "2021-12-02 17:28:16,347 - INFO - Epoch [10/100] train_loss: 2.8502, val_loss: 2.9499, lr: 0.003000, 43.74s\n",
      "2021-12-02 17:28:16,347 - INFO - Epoch [10/100] train_loss: 2.8502, val_loss: 2.9499, lr: 0.003000, 43.74s\n",
      "2021-12-02 17:28:16,347 - INFO - Epoch [10/100] train_loss: 2.8502, val_loss: 2.9499, lr: 0.003000, 43.74s\n",
      "2021-12-02 17:28:16,390 - INFO - Saved model at 10\n",
      "2021-12-02 17:28:16,390 - INFO - Saved model at 10\n",
      "2021-12-02 17:28:16,390 - INFO - Saved model at 10\n",
      "2021-12-02 17:28:16,394 - INFO - Val loss decrease from 2.9523 to 2.9499, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch10.tar\n",
      "2021-12-02 17:28:16,394 - INFO - Val loss decrease from 2.9523 to 2.9499, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch10.tar\n",
      "2021-12-02 17:28:16,394 - INFO - Val loss decrease from 2.9523 to 2.9499, saving to ./libcity/cache/model_cache/AGCRN_METR_LA_epoch10.tar\n",
      "2021-12-02 17:28:57,714 - INFO - epoch complete!\n",
      "2021-12-02 17:28:57,714 - INFO - epoch complete!\n",
      "2021-12-02 17:28:57,714 - INFO - epoch complete!\n",
      "2021-12-02 17:28:57,718 - INFO - evaluating now!\n",
      "2021-12-02 17:28:57,718 - INFO - evaluating now!\n",
      "2021-12-02 17:28:57,718 - INFO - evaluating now!\n",
      "2021-12-02 17:29:00,236 - INFO - Epoch [11/100] train_loss: 2.8195, val_loss: 2.9600, lr: 0.003000, 43.84s\n",
      "2021-12-02 17:29:00,236 - INFO - Epoch [11/100] train_loss: 2.8195, val_loss: 2.9600, lr: 0.003000, 43.84s\n",
      "2021-12-02 17:29:00,236 - INFO - Epoch [11/100] train_loss: 2.8195, val_loss: 2.9600, lr: 0.003000, 43.84s\n",
      "2021-12-02 17:29:41,994 - INFO - epoch complete!\n",
      "2021-12-02 17:29:41,994 - INFO - epoch complete!\n",
      "2021-12-02 17:29:41,994 - INFO - epoch complete!\n",
      "2021-12-02 17:29:41,997 - INFO - evaluating now!\n",
      "2021-12-02 17:29:41,997 - INFO - evaluating now!\n",
      "2021-12-02 17:29:41,997 - INFO - evaluating now!\n",
      "2021-12-02 17:29:44,572 - INFO - Epoch [12/100] train_loss: 2.7909, val_loss: 2.9850, lr: 0.003000, 44.33s\n",
      "2021-12-02 17:29:44,572 - INFO - Epoch [12/100] train_loss: 2.7909, val_loss: 2.9850, lr: 0.003000, 44.33s\n",
      "2021-12-02 17:29:44,572 - INFO - Epoch [12/100] train_loss: 2.7909, val_loss: 2.9850, lr: 0.003000, 44.33s\n",
      "2021-12-02 17:30:25,699 - INFO - epoch complete!\n",
      "2021-12-02 17:30:25,699 - INFO - epoch complete!\n",
      "2021-12-02 17:30:25,699 - INFO - epoch complete!\n",
      "2021-12-02 17:30:25,703 - INFO - evaluating now!\n",
      "2021-12-02 17:30:25,703 - INFO - evaluating now!\n",
      "2021-12-02 17:30:25,703 - INFO - evaluating now!\n",
      "2021-12-02 17:30:28,270 - INFO - Epoch [13/100] train_loss: 2.7684, val_loss: 2.9652, lr: 0.003000, 43.69s\n",
      "2021-12-02 17:30:28,270 - INFO - Epoch [13/100] train_loss: 2.7684, val_loss: 2.9652, lr: 0.003000, 43.69s\n",
      "2021-12-02 17:30:28,270 - INFO - Epoch [13/100] train_loss: 2.7684, val_loss: 2.9652, lr: 0.003000, 43.69s\n",
      "2021-12-02 17:31:10,517 - INFO - epoch complete!\n",
      "2021-12-02 17:31:10,517 - INFO - epoch complete!\n",
      "2021-12-02 17:31:10,517 - INFO - epoch complete!\n",
      "2021-12-02 17:31:10,522 - INFO - evaluating now!\n",
      "2021-12-02 17:31:10,522 - INFO - evaluating now!\n",
      "2021-12-02 17:31:10,522 - INFO - evaluating now!\n",
      "2021-12-02 17:31:13,114 - INFO - Epoch [14/100] train_loss: 2.7426, val_loss: 2.9815, lr: 0.003000, 44.84s\n",
      "2021-12-02 17:31:13,114 - INFO - Epoch [14/100] train_loss: 2.7426, val_loss: 2.9815, lr: 0.003000, 44.84s\n",
      "2021-12-02 17:31:13,114 - INFO - Epoch [14/100] train_loss: 2.7426, val_loss: 2.9815, lr: 0.003000, 44.84s\n",
      "2021-12-02 17:31:54,423 - INFO - epoch complete!\n",
      "2021-12-02 17:31:54,423 - INFO - epoch complete!\n",
      "2021-12-02 17:31:54,423 - INFO - epoch complete!\n",
      "2021-12-02 17:31:54,427 - INFO - evaluating now!\n",
      "2021-12-02 17:31:54,427 - INFO - evaluating now!\n",
      "2021-12-02 17:31:54,427 - INFO - evaluating now!\n",
      "2021-12-02 17:31:56,991 - INFO - Epoch [15/100] train_loss: 2.7193, val_loss: 2.9937, lr: 0.003000, 43.87s\n",
      "2021-12-02 17:31:56,991 - INFO - Epoch [15/100] train_loss: 2.7193, val_loss: 2.9937, lr: 0.003000, 43.87s\n",
      "2021-12-02 17:31:56,991 - INFO - Epoch [15/100] train_loss: 2.7193, val_loss: 2.9937, lr: 0.003000, 43.87s\n",
      "2021-12-02 17:32:38,166 - INFO - epoch complete!\n",
      "2021-12-02 17:32:38,166 - INFO - epoch complete!\n",
      "2021-12-02 17:32:38,166 - INFO - epoch complete!\n",
      "2021-12-02 17:32:38,171 - INFO - evaluating now!\n",
      "2021-12-02 17:32:38,171 - INFO - evaluating now!\n",
      "2021-12-02 17:32:38,171 - INFO - evaluating now!\n",
      "2021-12-02 17:32:40,744 - INFO - Epoch [16/100] train_loss: 2.6958, val_loss: 2.9605, lr: 0.003000, 43.75s\n",
      "2021-12-02 17:32:40,744 - INFO - Epoch [16/100] train_loss: 2.6958, val_loss: 2.9605, lr: 0.003000, 43.75s\n",
      "2021-12-02 17:32:40,744 - INFO - Epoch [16/100] train_loss: 2.6958, val_loss: 2.9605, lr: 0.003000, 43.75s\n",
      "2021-12-02 17:33:22,537 - INFO - epoch complete!\n",
      "2021-12-02 17:33:22,537 - INFO - epoch complete!\n",
      "2021-12-02 17:33:22,537 - INFO - epoch complete!\n",
      "2021-12-02 17:33:22,542 - INFO - evaluating now!\n",
      "2021-12-02 17:33:22,542 - INFO - evaluating now!\n",
      "2021-12-02 17:33:22,542 - INFO - evaluating now!\n",
      "2021-12-02 17:33:25,158 - INFO - Epoch [17/100] train_loss: 2.6740, val_loss: 2.9931, lr: 0.003000, 44.41s\n",
      "2021-12-02 17:33:25,158 - INFO - Epoch [17/100] train_loss: 2.6740, val_loss: 2.9931, lr: 0.003000, 44.41s\n",
      "2021-12-02 17:33:25,158 - INFO - Epoch [17/100] train_loss: 2.6740, val_loss: 2.9931, lr: 0.003000, 44.41s\n",
      "2021-12-02 17:34:06,169 - INFO - epoch complete!\n",
      "2021-12-02 17:34:06,169 - INFO - epoch complete!\n",
      "2021-12-02 17:34:06,169 - INFO - epoch complete!\n",
      "2021-12-02 17:34:06,174 - INFO - evaluating now!\n",
      "2021-12-02 17:34:06,174 - INFO - evaluating now!\n",
      "2021-12-02 17:34:06,174 - INFO - evaluating now!\n",
      "2021-12-02 17:34:08,676 - INFO - Epoch [18/100] train_loss: 2.6517, val_loss: 2.9849, lr: 0.003000, 43.51s\n",
      "2021-12-02 17:34:08,676 - INFO - Epoch [18/100] train_loss: 2.6517, val_loss: 2.9849, lr: 0.003000, 43.51s\n",
      "2021-12-02 17:34:08,676 - INFO - Epoch [18/100] train_loss: 2.6517, val_loss: 2.9849, lr: 0.003000, 43.51s\n",
      "2021-12-02 17:34:49,805 - INFO - epoch complete!\n",
      "2021-12-02 17:34:49,805 - INFO - epoch complete!\n",
      "2021-12-02 17:34:49,805 - INFO - epoch complete!\n",
      "2021-12-02 17:34:49,809 - INFO - evaluating now!\n",
      "2021-12-02 17:34:49,809 - INFO - evaluating now!\n",
      "2021-12-02 17:34:49,809 - INFO - evaluating now!\n",
      "2021-12-02 17:34:52,296 - INFO - Epoch [19/100] train_loss: 2.6331, val_loss: 2.9969, lr: 0.003000, 43.61s\n",
      "2021-12-02 17:34:52,296 - INFO - Epoch [19/100] train_loss: 2.6331, val_loss: 2.9969, lr: 0.003000, 43.61s\n",
      "2021-12-02 17:34:52,296 - INFO - Epoch [19/100] train_loss: 2.6331, val_loss: 2.9969, lr: 0.003000, 43.61s\n",
      "2021-12-02 17:35:33,471 - INFO - epoch complete!\n",
      "2021-12-02 17:35:33,471 - INFO - epoch complete!\n",
      "2021-12-02 17:35:33,471 - INFO - epoch complete!\n",
      "2021-12-02 17:35:33,476 - INFO - evaluating now!\n",
      "2021-12-02 17:35:33,476 - INFO - evaluating now!\n",
      "2021-12-02 17:35:33,476 - INFO - evaluating now!\n",
      "2021-12-02 17:35:35,926 - INFO - Epoch [20/100] train_loss: 2.6137, val_loss: 2.9889, lr: 0.003000, 43.63s\n",
      "2021-12-02 17:35:35,926 - INFO - Epoch [20/100] train_loss: 2.6137, val_loss: 2.9889, lr: 0.003000, 43.63s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:35:35,926 - INFO - Epoch [20/100] train_loss: 2.6137, val_loss: 2.9889, lr: 0.003000, 43.63s\n",
      "2021-12-02 17:36:17,751 - INFO - epoch complete!\n",
      "2021-12-02 17:36:17,751 - INFO - epoch complete!\n",
      "2021-12-02 17:36:17,751 - INFO - epoch complete!\n",
      "2021-12-02 17:36:17,756 - INFO - evaluating now!\n",
      "2021-12-02 17:36:17,756 - INFO - evaluating now!\n",
      "2021-12-02 17:36:17,756 - INFO - evaluating now!\n",
      "2021-12-02 17:36:20,371 - INFO - Epoch [21/100] train_loss: 2.5963, val_loss: 3.0145, lr: 0.003000, 44.44s\n",
      "2021-12-02 17:36:20,371 - INFO - Epoch [21/100] train_loss: 2.5963, val_loss: 3.0145, lr: 0.003000, 44.44s\n",
      "2021-12-02 17:36:20,371 - INFO - Epoch [21/100] train_loss: 2.5963, val_loss: 3.0145, lr: 0.003000, 44.44s\n",
      "2021-12-02 17:37:01,761 - INFO - epoch complete!\n",
      "2021-12-02 17:37:01,761 - INFO - epoch complete!\n",
      "2021-12-02 17:37:01,761 - INFO - epoch complete!\n",
      "2021-12-02 17:37:01,766 - INFO - evaluating now!\n",
      "2021-12-02 17:37:01,766 - INFO - evaluating now!\n",
      "2021-12-02 17:37:01,766 - INFO - evaluating now!\n",
      "2021-12-02 17:37:04,438 - INFO - Epoch [22/100] train_loss: 2.5803, val_loss: 3.0364, lr: 0.003000, 44.06s\n",
      "2021-12-02 17:37:04,438 - INFO - Epoch [22/100] train_loss: 2.5803, val_loss: 3.0364, lr: 0.003000, 44.06s\n",
      "2021-12-02 17:37:04,438 - INFO - Epoch [22/100] train_loss: 2.5803, val_loss: 3.0364, lr: 0.003000, 44.06s\n",
      "2021-12-02 17:37:46,090 - INFO - epoch complete!\n",
      "2021-12-02 17:37:46,090 - INFO - epoch complete!\n",
      "2021-12-02 17:37:46,090 - INFO - epoch complete!\n",
      "2021-12-02 17:37:46,095 - INFO - evaluating now!\n",
      "2021-12-02 17:37:46,095 - INFO - evaluating now!\n",
      "2021-12-02 17:37:46,095 - INFO - evaluating now!\n",
      "2021-12-02 17:37:48,662 - INFO - Epoch [23/100] train_loss: 2.5708, val_loss: 3.0223, lr: 0.003000, 44.22s\n",
      "2021-12-02 17:37:48,662 - INFO - Epoch [23/100] train_loss: 2.5708, val_loss: 3.0223, lr: 0.003000, 44.22s\n",
      "2021-12-02 17:37:48,662 - INFO - Epoch [23/100] train_loss: 2.5708, val_loss: 3.0223, lr: 0.003000, 44.22s\n",
      "2021-12-02 17:38:30,996 - INFO - epoch complete!\n",
      "2021-12-02 17:38:30,996 - INFO - epoch complete!\n",
      "2021-12-02 17:38:30,996 - INFO - epoch complete!\n",
      "2021-12-02 17:38:31,001 - INFO - evaluating now!\n",
      "2021-12-02 17:38:31,001 - INFO - evaluating now!\n",
      "2021-12-02 17:38:31,001 - INFO - evaluating now!\n",
      "2021-12-02 17:38:33,489 - INFO - Epoch [24/100] train_loss: 2.5539, val_loss: 3.0233, lr: 0.003000, 44.82s\n",
      "2021-12-02 17:38:33,489 - INFO - Epoch [24/100] train_loss: 2.5539, val_loss: 3.0233, lr: 0.003000, 44.82s\n",
      "2021-12-02 17:38:33,489 - INFO - Epoch [24/100] train_loss: 2.5539, val_loss: 3.0233, lr: 0.003000, 44.82s\n",
      "2021-12-02 17:39:14,162 - INFO - epoch complete!\n",
      "2021-12-02 17:39:14,162 - INFO - epoch complete!\n",
      "2021-12-02 17:39:14,162 - INFO - epoch complete!\n",
      "2021-12-02 17:39:14,167 - INFO - evaluating now!\n",
      "2021-12-02 17:39:14,167 - INFO - evaluating now!\n",
      "2021-12-02 17:39:14,167 - INFO - evaluating now!\n",
      "2021-12-02 17:39:16,683 - INFO - Epoch [25/100] train_loss: 2.5408, val_loss: 3.0229, lr: 0.003000, 43.19s\n",
      "2021-12-02 17:39:16,683 - INFO - Epoch [25/100] train_loss: 2.5408, val_loss: 3.0229, lr: 0.003000, 43.19s\n",
      "2021-12-02 17:39:16,683 - INFO - Epoch [25/100] train_loss: 2.5408, val_loss: 3.0229, lr: 0.003000, 43.19s\n",
      "2021-12-02 17:39:16,688 - WARNING - Early stopping at epoch: 25\n",
      "2021-12-02 17:39:16,688 - WARNING - Early stopping at epoch: 25\n",
      "2021-12-02 17:39:16,688 - WARNING - Early stopping at epoch: 25\n",
      "2021-12-02 17:39:16,690 - INFO - Trained totally 26 epochs, average train time is 41.279s, average eval time is 2.543s\n",
      "2021-12-02 17:39:16,690 - INFO - Trained totally 26 epochs, average train time is 41.279s, average eval time is 2.543s\n",
      "2021-12-02 17:39:16,690 - INFO - Trained totally 26 epochs, average train time is 41.279s, average eval time is 2.543s\n",
      "2021-12-02 17:39:16,711 - INFO - Loaded model at 10\n",
      "2021-12-02 17:39:16,711 - INFO - Loaded model at 10\n",
      "2021-12-02 17:39:16,711 - INFO - Loaded model at 10\n",
      "2021-12-02 17:39:16,714 - INFO - Saved model at ./libcity/cache/model_cache/AGCRN_METR_LA.m\n",
      "2021-12-02 17:39:16,714 - INFO - Saved model at ./libcity/cache/model_cache/AGCRN_METR_LA.m\n",
      "2021-12-02 17:39:16,714 - INFO - Saved model at ./libcity/cache/model_cache/AGCRN_METR_LA.m\n",
      "2021-12-02 17:39:16,749 - INFO - Loaded model at ./libcity/cache/model_cache/AGCRN_METR_LA.m\n",
      "2021-12-02 17:39:16,749 - INFO - Loaded model at ./libcity/cache/model_cache/AGCRN_METR_LA.m\n",
      "2021-12-02 17:39:16,749 - INFO - Loaded model at ./libcity/cache/model_cache/AGCRN_METR_LA.m\n",
      "2021-12-02 17:39:16,762 - INFO - Start evaluating ...\n",
      "2021-12-02 17:39:16,762 - INFO - Start evaluating ...\n",
      "2021-12-02 17:39:16,762 - INFO - Start evaluating ...\n",
      "2021-12-02 17:39:28,817 - INFO - Note that you select the single mode to evaluate!\n",
      "2021-12-02 17:39:28,817 - INFO - Note that you select the single mode to evaluate!\n",
      "2021-12-02 17:39:28,817 - INFO - Note that you select the single mode to evaluate!\n",
      "2021-12-02 17:39:28,820 - INFO - Evaluate result is {\"MAE@1\": 8.890697479248047, \"MAPE@1\": Infinity, \"MSE@1\": 420.39337158203125, \"RMSE@1\": 20.503496170043945, \"masked_MAE@1\": 2.4045143127441406, \"masked_MSE@1\": 18.11513328552246, \"masked_RMSE@1\": 4.256187438964844, \"masked_MAPE@1\": 0.061000507324934006, \"R2@1\": 0.18928243592607863, \"EVAR@1\": 0.2842714190483093, \"MAE@2\": 9.189087867736816, \"MAPE@2\": Infinity, \"MSE@2\": 432.1625671386719, \"RMSE@2\": 20.78852081298828, \"masked_MAE@2\": 2.666740655899048, \"masked_MSE@2\": 25.265684127807617, \"masked_RMSE@2\": 5.026498317718506, \"masked_MAPE@2\": 0.06985758244991302, \"R2@2\": 0.166607016418726, \"EVAR@2\": 0.2657508850097656, \"MAE@3\": 9.442975997924805, \"MAPE@3\": Infinity, \"MSE@3\": 444.35308837890625, \"RMSE@3\": 21.079683303833008, \"masked_MAE@3\": 2.860224962234497, \"masked_MSE@3\": 30.716676712036133, \"masked_RMSE@3\": 5.542262554168701, \"masked_MAPE@3\": 0.07655974477529526, \"R2@3\": 0.14311973728292582, \"EVAR@3\": 0.24535918235778809, \"MAE@4\": 9.68348217010498, \"MAPE@4\": Infinity, \"MSE@4\": 458.26690673828125, \"RMSE@4\": 21.407169342041016, \"masked_MAE@4\": 3.0167880058288574, \"masked_MSE@4\": 35.383113861083984, \"masked_RMSE@4\": 5.948370456695557, \"masked_MAPE@4\": 0.08255864679813385, \"R2@4\": 0.11631766295507895, \"EVAR@4\": 0.22125405073165894, \"MAE@5\": 9.854841232299805, \"MAPE@5\": Infinity, \"MSE@5\": 469.08148193359375, \"RMSE@5\": 21.658288955688477, \"masked_MAE@5\": 3.1302249431610107, \"masked_MSE@5\": 39.579036712646484, \"masked_RMSE@5\": 6.291187286376953, \"masked_MAPE@5\": 0.08707014471292496, \"R2@5\": 0.09549042276317365, \"EVAR@5\": 0.20570355653762817, \"MAE@6\": 9.988621711730957, \"MAPE@6\": Infinity, \"MSE@6\": 477.4897766113281, \"RMSE@6\": 21.851539611816406, \"masked_MAE@6\": 3.226783037185669, \"masked_MSE@6\": 42.979312896728516, \"masked_RMSE@6\": 6.555860996246338, \"masked_MAPE@6\": 0.08997208625078201, \"R2@6\": 0.07929648567688463, \"EVAR@6\": 0.19013231992721558, \"MAE@7\": 10.088787078857422, \"MAPE@7\": Infinity, \"MSE@7\": 481.89105224609375, \"RMSE@7\": 21.952016830444336, \"masked_MAE@7\": 3.314007520675659, \"masked_MSE@7\": 45.6368408203125, \"masked_RMSE@7\": 6.755504608154297, \"masked_MAPE@7\": 0.09309586137533188, \"R2@7\": 0.07083708752044071, \"EVAR@7\": 0.18194067478179932, \"MAE@8\": 10.188614845275879, \"MAPE@8\": Infinity, \"MSE@8\": 487.81964111328125, \"RMSE@8\": 22.086639404296875, \"masked_MAE@8\": 3.387669801712036, \"masked_MSE@8\": 48.29191589355469, \"masked_RMSE@8\": 6.949238300323486, \"masked_MAPE@8\": 0.09593810886144638, \"R2@8\": 0.059432328964293624, \"EVAR@8\": 0.1742979884147644, \"MAE@9\": 10.257475852966309, \"MAPE@9\": Infinity, \"MSE@9\": 490.9385070800781, \"RMSE@9\": 22.157133102416992, \"masked_MAE@9\": 3.4516327381134033, \"masked_MSE@9\": 50.66089630126953, \"masked_RMSE@9\": 7.11764669418335, \"masked_MAPE@9\": 0.09825744479894638, \"R2@9\": 0.053444930057119255, \"EVAR@9\": 0.16926217079162598, \"MAE@10\": 10.316076278686523, \"MAPE@10\": Infinity, \"MSE@10\": 493.4727783203125, \"RMSE@10\": 22.21424674987793, \"masked_MAE@10\": 3.5085959434509277, \"masked_MSE@10\": 52.87675857543945, \"masked_RMSE@10\": 7.271640777587891, \"masked_MAPE@10\": 0.10032305866479874, \"R2@10\": 0.048589805815067555, \"EVAR@10\": 0.16471248865127563, \"MAE@11\": 10.376492500305176, \"MAPE@11\": Infinity, \"MSE@11\": 496.6549072265625, \"RMSE@11\": 22.285755157470703, \"masked_MAE@11\": 3.5643386840820312, \"masked_MSE@11\": 54.999664306640625, \"masked_RMSE@11\": 7.416175842285156, \"masked_MAPE@11\": 0.10205601900815964, \"R2@11\": 0.04248482171547352, \"EVAR@11\": 0.15960931777954102, \"MAE@12\": 10.439260482788086, \"MAPE@12\": Infinity, \"MSE@12\": 498.5731506347656, \"RMSE@12\": 22.328752517700195, \"masked_MAE@12\": 3.6279025077819824, \"masked_MSE@12\": 56.821537017822266, \"masked_RMSE@12\": 7.53800630569458, \"masked_MAPE@12\": 0.10457180440425873, \"R2@12\": 0.03881477090159824, \"EVAR@12\": 0.1569414734840393}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:39:28,820 - INFO - Evaluate result is {\"MAE@1\": 8.890697479248047, \"MAPE@1\": Infinity, \"MSE@1\": 420.39337158203125, \"RMSE@1\": 20.503496170043945, \"masked_MAE@1\": 2.4045143127441406, \"masked_MSE@1\": 18.11513328552246, \"masked_RMSE@1\": 4.256187438964844, \"masked_MAPE@1\": 0.061000507324934006, \"R2@1\": 0.18928243592607863, \"EVAR@1\": 0.2842714190483093, \"MAE@2\": 9.189087867736816, \"MAPE@2\": Infinity, \"MSE@2\": 432.1625671386719, \"RMSE@2\": 20.78852081298828, \"masked_MAE@2\": 2.666740655899048, \"masked_MSE@2\": 25.265684127807617, \"masked_RMSE@2\": 5.026498317718506, \"masked_MAPE@2\": 0.06985758244991302, \"R2@2\": 0.166607016418726, \"EVAR@2\": 0.2657508850097656, \"MAE@3\": 9.442975997924805, \"MAPE@3\": Infinity, \"MSE@3\": 444.35308837890625, \"RMSE@3\": 21.079683303833008, \"masked_MAE@3\": 2.860224962234497, \"masked_MSE@3\": 30.716676712036133, \"masked_RMSE@3\": 5.542262554168701, \"masked_MAPE@3\": 0.07655974477529526, \"R2@3\": 0.14311973728292582, \"EVAR@3\": 0.24535918235778809, \"MAE@4\": 9.68348217010498, \"MAPE@4\": Infinity, \"MSE@4\": 458.26690673828125, \"RMSE@4\": 21.407169342041016, \"masked_MAE@4\": 3.0167880058288574, \"masked_MSE@4\": 35.383113861083984, \"masked_RMSE@4\": 5.948370456695557, \"masked_MAPE@4\": 0.08255864679813385, \"R2@4\": 0.11631766295507895, \"EVAR@4\": 0.22125405073165894, \"MAE@5\": 9.854841232299805, \"MAPE@5\": Infinity, \"MSE@5\": 469.08148193359375, \"RMSE@5\": 21.658288955688477, \"masked_MAE@5\": 3.1302249431610107, \"masked_MSE@5\": 39.579036712646484, \"masked_RMSE@5\": 6.291187286376953, \"masked_MAPE@5\": 0.08707014471292496, \"R2@5\": 0.09549042276317365, \"EVAR@5\": 0.20570355653762817, \"MAE@6\": 9.988621711730957, \"MAPE@6\": Infinity, \"MSE@6\": 477.4897766113281, \"RMSE@6\": 21.851539611816406, \"masked_MAE@6\": 3.226783037185669, \"masked_MSE@6\": 42.979312896728516, \"masked_RMSE@6\": 6.555860996246338, \"masked_MAPE@6\": 0.08997208625078201, \"R2@6\": 0.07929648567688463, \"EVAR@6\": 0.19013231992721558, \"MAE@7\": 10.088787078857422, \"MAPE@7\": Infinity, \"MSE@7\": 481.89105224609375, \"RMSE@7\": 21.952016830444336, \"masked_MAE@7\": 3.314007520675659, \"masked_MSE@7\": 45.6368408203125, \"masked_RMSE@7\": 6.755504608154297, \"masked_MAPE@7\": 0.09309586137533188, \"R2@7\": 0.07083708752044071, \"EVAR@7\": 0.18194067478179932, \"MAE@8\": 10.188614845275879, \"MAPE@8\": Infinity, \"MSE@8\": 487.81964111328125, \"RMSE@8\": 22.086639404296875, \"masked_MAE@8\": 3.387669801712036, \"masked_MSE@8\": 48.29191589355469, \"masked_RMSE@8\": 6.949238300323486, \"masked_MAPE@8\": 0.09593810886144638, \"R2@8\": 0.059432328964293624, \"EVAR@8\": 0.1742979884147644, \"MAE@9\": 10.257475852966309, \"MAPE@9\": Infinity, \"MSE@9\": 490.9385070800781, \"RMSE@9\": 22.157133102416992, \"masked_MAE@9\": 3.4516327381134033, \"masked_MSE@9\": 50.66089630126953, \"masked_RMSE@9\": 7.11764669418335, \"masked_MAPE@9\": 0.09825744479894638, \"R2@9\": 0.053444930057119255, \"EVAR@9\": 0.16926217079162598, \"MAE@10\": 10.316076278686523, \"MAPE@10\": Infinity, \"MSE@10\": 493.4727783203125, \"RMSE@10\": 22.21424674987793, \"masked_MAE@10\": 3.5085959434509277, \"masked_MSE@10\": 52.87675857543945, \"masked_RMSE@10\": 7.271640777587891, \"masked_MAPE@10\": 0.10032305866479874, \"R2@10\": 0.048589805815067555, \"EVAR@10\": 0.16471248865127563, \"MAE@11\": 10.376492500305176, \"MAPE@11\": Infinity, \"MSE@11\": 496.6549072265625, \"RMSE@11\": 22.285755157470703, \"masked_MAE@11\": 3.5643386840820312, \"masked_MSE@11\": 54.999664306640625, \"masked_RMSE@11\": 7.416175842285156, \"masked_MAPE@11\": 0.10205601900815964, \"R2@11\": 0.04248482171547352, \"EVAR@11\": 0.15960931777954102, \"MAE@12\": 10.439260482788086, \"MAPE@12\": Infinity, \"MSE@12\": 498.5731506347656, \"RMSE@12\": 22.328752517700195, \"masked_MAE@12\": 3.6279025077819824, \"masked_MSE@12\": 56.821537017822266, \"masked_RMSE@12\": 7.53800630569458, \"masked_MAPE@12\": 0.10457180440425873, \"R2@12\": 0.03881477090159824, \"EVAR@12\": 0.1569414734840393}\n",
      "2021-12-02 17:39:28,820 - INFO - Evaluate result is {\"MAE@1\": 8.890697479248047, \"MAPE@1\": Infinity, \"MSE@1\": 420.39337158203125, \"RMSE@1\": 20.503496170043945, \"masked_MAE@1\": 2.4045143127441406, \"masked_MSE@1\": 18.11513328552246, \"masked_RMSE@1\": 4.256187438964844, \"masked_MAPE@1\": 0.061000507324934006, \"R2@1\": 0.18928243592607863, \"EVAR@1\": 0.2842714190483093, \"MAE@2\": 9.189087867736816, \"MAPE@2\": Infinity, \"MSE@2\": 432.1625671386719, \"RMSE@2\": 20.78852081298828, \"masked_MAE@2\": 2.666740655899048, \"masked_MSE@2\": 25.265684127807617, \"masked_RMSE@2\": 5.026498317718506, \"masked_MAPE@2\": 0.06985758244991302, \"R2@2\": 0.166607016418726, \"EVAR@2\": 0.2657508850097656, \"MAE@3\": 9.442975997924805, \"MAPE@3\": Infinity, \"MSE@3\": 444.35308837890625, \"RMSE@3\": 21.079683303833008, \"masked_MAE@3\": 2.860224962234497, \"masked_MSE@3\": 30.716676712036133, \"masked_RMSE@3\": 5.542262554168701, \"masked_MAPE@3\": 0.07655974477529526, \"R2@3\": 0.14311973728292582, \"EVAR@3\": 0.24535918235778809, \"MAE@4\": 9.68348217010498, \"MAPE@4\": Infinity, \"MSE@4\": 458.26690673828125, \"RMSE@4\": 21.407169342041016, \"masked_MAE@4\": 3.0167880058288574, \"masked_MSE@4\": 35.383113861083984, \"masked_RMSE@4\": 5.948370456695557, \"masked_MAPE@4\": 0.08255864679813385, \"R2@4\": 0.11631766295507895, \"EVAR@4\": 0.22125405073165894, \"MAE@5\": 9.854841232299805, \"MAPE@5\": Infinity, \"MSE@5\": 469.08148193359375, \"RMSE@5\": 21.658288955688477, \"masked_MAE@5\": 3.1302249431610107, \"masked_MSE@5\": 39.579036712646484, \"masked_RMSE@5\": 6.291187286376953, \"masked_MAPE@5\": 0.08707014471292496, \"R2@5\": 0.09549042276317365, \"EVAR@5\": 0.20570355653762817, \"MAE@6\": 9.988621711730957, \"MAPE@6\": Infinity, \"MSE@6\": 477.4897766113281, \"RMSE@6\": 21.851539611816406, \"masked_MAE@6\": 3.226783037185669, \"masked_MSE@6\": 42.979312896728516, \"masked_RMSE@6\": 6.555860996246338, \"masked_MAPE@6\": 0.08997208625078201, \"R2@6\": 0.07929648567688463, \"EVAR@6\": 0.19013231992721558, \"MAE@7\": 10.088787078857422, \"MAPE@7\": Infinity, \"MSE@7\": 481.89105224609375, \"RMSE@7\": 21.952016830444336, \"masked_MAE@7\": 3.314007520675659, \"masked_MSE@7\": 45.6368408203125, \"masked_RMSE@7\": 6.755504608154297, \"masked_MAPE@7\": 0.09309586137533188, \"R2@7\": 0.07083708752044071, \"EVAR@7\": 0.18194067478179932, \"MAE@8\": 10.188614845275879, \"MAPE@8\": Infinity, \"MSE@8\": 487.81964111328125, \"RMSE@8\": 22.086639404296875, \"masked_MAE@8\": 3.387669801712036, \"masked_MSE@8\": 48.29191589355469, \"masked_RMSE@8\": 6.949238300323486, \"masked_MAPE@8\": 0.09593810886144638, \"R2@8\": 0.059432328964293624, \"EVAR@8\": 0.1742979884147644, \"MAE@9\": 10.257475852966309, \"MAPE@9\": Infinity, \"MSE@9\": 490.9385070800781, \"RMSE@9\": 22.157133102416992, \"masked_MAE@9\": 3.4516327381134033, \"masked_MSE@9\": 50.66089630126953, \"masked_RMSE@9\": 7.11764669418335, \"masked_MAPE@9\": 0.09825744479894638, \"R2@9\": 0.053444930057119255, \"EVAR@9\": 0.16926217079162598, \"MAE@10\": 10.316076278686523, \"MAPE@10\": Infinity, \"MSE@10\": 493.4727783203125, \"RMSE@10\": 22.21424674987793, \"masked_MAE@10\": 3.5085959434509277, \"masked_MSE@10\": 52.87675857543945, \"masked_RMSE@10\": 7.271640777587891, \"masked_MAPE@10\": 0.10032305866479874, \"R2@10\": 0.048589805815067555, \"EVAR@10\": 0.16471248865127563, \"MAE@11\": 10.376492500305176, \"MAPE@11\": Infinity, \"MSE@11\": 496.6549072265625, \"RMSE@11\": 22.285755157470703, \"masked_MAE@11\": 3.5643386840820312, \"masked_MSE@11\": 54.999664306640625, \"masked_RMSE@11\": 7.416175842285156, \"masked_MAPE@11\": 0.10205601900815964, \"R2@11\": 0.04248482171547352, \"EVAR@11\": 0.15960931777954102, \"MAE@12\": 10.439260482788086, \"MAPE@12\": Infinity, \"MSE@12\": 498.5731506347656, \"RMSE@12\": 22.328752517700195, \"masked_MAE@12\": 3.6279025077819824, \"masked_MSE@12\": 56.821537017822266, \"masked_RMSE@12\": 7.53800630569458, \"masked_MAPE@12\": 0.10457180440425873, \"R2@12\": 0.03881477090159824, \"EVAR@12\": 0.1569414734840393}\n",
      "2021-12-02 17:39:28,824 - INFO - Evaluate result is saved at ./libcity/cache/evaluate_cache/2021_12_02_17_39_28_AGCRN_METR_LA.json\n",
      "2021-12-02 17:39:28,824 - INFO - Evaluate result is saved at ./libcity/cache/evaluate_cache/2021_12_02_17_39_28_AGCRN_METR_LA.json\n",
      "2021-12-02 17:39:28,824 - INFO - Evaluate result is saved at ./libcity/cache/evaluate_cache/2021_12_02_17_39_28_AGCRN_METR_LA.json\n",
      "2021-12-02 17:39:28,830 - INFO - Evaluate result is saved at ./libcity/cache/evaluate_cache/2021_12_02_17_39_28_AGCRN_METR_LA.csv\n",
      "2021-12-02 17:39:28,830 - INFO - Evaluate result is saved at ./libcity/cache/evaluate_cache/2021_12_02_17_39_28_AGCRN_METR_LA.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:39:28,830 - INFO - Evaluate result is saved at ./libcity/cache/evaluate_cache/2021_12_02_17_39_28_AGCRN_METR_LA.csv\n",
      "2021-12-02 17:39:28,837 - INFO - \n",
      "          MAE  MAPE         MSE       RMSE  masked_MAE  masked_MSE  \\\n",
      "1    8.890697   inf  420.393372  20.503496    2.404514   18.115133   \n",
      "2    9.189088   inf  432.162567  20.788521    2.666741   25.265684   \n",
      "3    9.442976   inf  444.353088  21.079683    2.860225   30.716677   \n",
      "4    9.683482   inf  458.266907  21.407169    3.016788   35.383114   \n",
      "5    9.854841   inf  469.081482  21.658289    3.130225   39.579037   \n",
      "6    9.988622   inf  477.489777  21.851540    3.226783   42.979313   \n",
      "7   10.088787   inf  481.891052  21.952017    3.314008   45.636841   \n",
      "8   10.188615   inf  487.819641  22.086639    3.387670   48.291916   \n",
      "9   10.257476   inf  490.938507  22.157133    3.451633   50.660896   \n",
      "10  10.316076   inf  493.472778  22.214247    3.508596   52.876759   \n",
      "11  10.376493   inf  496.654907  22.285755    3.564339   54.999664   \n",
      "12  10.439260   inf  498.573151  22.328753    3.627903   56.821537   \n",
      "\n",
      "    masked_RMSE  masked_MAPE        R2      EVAR  \n",
      "1      4.256187     0.061001  0.189282  0.284271  \n",
      "2      5.026498     0.069858  0.166607  0.265751  \n",
      "3      5.542263     0.076560  0.143120  0.245359  \n",
      "4      5.948370     0.082559  0.116318  0.221254  \n",
      "5      6.291187     0.087070  0.095490  0.205704  \n",
      "6      6.555861     0.089972  0.079296  0.190132  \n",
      "7      6.755505     0.093096  0.070837  0.181941  \n",
      "8      6.949238     0.095938  0.059432  0.174298  \n",
      "9      7.117647     0.098257  0.053445  0.169262  \n",
      "10     7.271641     0.100323  0.048590  0.164712  \n",
      "11     7.416176     0.102056  0.042485  0.159609  \n",
      "12     7.538006     0.104572  0.038815  0.156941  \n",
      "2021-12-02 17:39:28,837 - INFO - \n",
      "          MAE  MAPE         MSE       RMSE  masked_MAE  masked_MSE  \\\n",
      "1    8.890697   inf  420.393372  20.503496    2.404514   18.115133   \n",
      "2    9.189088   inf  432.162567  20.788521    2.666741   25.265684   \n",
      "3    9.442976   inf  444.353088  21.079683    2.860225   30.716677   \n",
      "4    9.683482   inf  458.266907  21.407169    3.016788   35.383114   \n",
      "5    9.854841   inf  469.081482  21.658289    3.130225   39.579037   \n",
      "6    9.988622   inf  477.489777  21.851540    3.226783   42.979313   \n",
      "7   10.088787   inf  481.891052  21.952017    3.314008   45.636841   \n",
      "8   10.188615   inf  487.819641  22.086639    3.387670   48.291916   \n",
      "9   10.257476   inf  490.938507  22.157133    3.451633   50.660896   \n",
      "10  10.316076   inf  493.472778  22.214247    3.508596   52.876759   \n",
      "11  10.376493   inf  496.654907  22.285755    3.564339   54.999664   \n",
      "12  10.439260   inf  498.573151  22.328753    3.627903   56.821537   \n",
      "\n",
      "    masked_RMSE  masked_MAPE        R2      EVAR  \n",
      "1      4.256187     0.061001  0.189282  0.284271  \n",
      "2      5.026498     0.069858  0.166607  0.265751  \n",
      "3      5.542263     0.076560  0.143120  0.245359  \n",
      "4      5.948370     0.082559  0.116318  0.221254  \n",
      "5      6.291187     0.087070  0.095490  0.205704  \n",
      "6      6.555861     0.089972  0.079296  0.190132  \n",
      "7      6.755505     0.093096  0.070837  0.181941  \n",
      "8      6.949238     0.095938  0.059432  0.174298  \n",
      "9      7.117647     0.098257  0.053445  0.169262  \n",
      "10     7.271641     0.100323  0.048590  0.164712  \n",
      "11     7.416176     0.102056  0.042485  0.159609  \n",
      "12     7.538006     0.104572  0.038815  0.156941  \n",
      "2021-12-02 17:39:28,837 - INFO - \n",
      "          MAE  MAPE         MSE       RMSE  masked_MAE  masked_MSE  \\\n",
      "1    8.890697   inf  420.393372  20.503496    2.404514   18.115133   \n",
      "2    9.189088   inf  432.162567  20.788521    2.666741   25.265684   \n",
      "3    9.442976   inf  444.353088  21.079683    2.860225   30.716677   \n",
      "4    9.683482   inf  458.266907  21.407169    3.016788   35.383114   \n",
      "5    9.854841   inf  469.081482  21.658289    3.130225   39.579037   \n",
      "6    9.988622   inf  477.489777  21.851540    3.226783   42.979313   \n",
      "7   10.088787   inf  481.891052  21.952017    3.314008   45.636841   \n",
      "8   10.188615   inf  487.819641  22.086639    3.387670   48.291916   \n",
      "9   10.257476   inf  490.938507  22.157133    3.451633   50.660896   \n",
      "10  10.316076   inf  493.472778  22.214247    3.508596   52.876759   \n",
      "11  10.376493   inf  496.654907  22.285755    3.564339   54.999664   \n",
      "12  10.439260   inf  498.573151  22.328753    3.627903   56.821537   \n",
      "\n",
      "    masked_RMSE  masked_MAPE        R2      EVAR  \n",
      "1      4.256187     0.061001  0.189282  0.284271  \n",
      "2      5.026498     0.069858  0.166607  0.265751  \n",
      "3      5.542263     0.076560  0.143120  0.245359  \n",
      "4      5.948370     0.082559  0.116318  0.221254  \n",
      "5      6.291187     0.087070  0.095490  0.205704  \n",
      "6      6.555861     0.089972  0.079296  0.190132  \n",
      "7      6.755505     0.093096  0.070837  0.181941  \n",
      "8      6.949238     0.095938  0.059432  0.174298  \n",
      "9      7.117647     0.098257  0.053445  0.169262  \n",
      "10     7.271641     0.100323  0.048590  0.164712  \n",
      "11     7.416176     0.102056  0.042485  0.159609  \n",
      "12     7.538006     0.104572  0.038815  0.156941  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>masked_MAE</th>\n",
       "      <th>masked_MSE</th>\n",
       "      <th>masked_RMSE</th>\n",
       "      <th>masked_MAPE</th>\n",
       "      <th>R2</th>\n",
       "      <th>EVAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.890697</td>\n",
       "      <td>inf</td>\n",
       "      <td>420.393372</td>\n",
       "      <td>20.503496</td>\n",
       "      <td>2.404514</td>\n",
       "      <td>18.115133</td>\n",
       "      <td>4.256187</td>\n",
       "      <td>0.061001</td>\n",
       "      <td>0.189282</td>\n",
       "      <td>0.284271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.189088</td>\n",
       "      <td>inf</td>\n",
       "      <td>432.162567</td>\n",
       "      <td>20.788521</td>\n",
       "      <td>2.666741</td>\n",
       "      <td>25.265684</td>\n",
       "      <td>5.026498</td>\n",
       "      <td>0.069858</td>\n",
       "      <td>0.166607</td>\n",
       "      <td>0.265751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.442976</td>\n",
       "      <td>inf</td>\n",
       "      <td>444.353088</td>\n",
       "      <td>21.079683</td>\n",
       "      <td>2.860225</td>\n",
       "      <td>30.716677</td>\n",
       "      <td>5.542263</td>\n",
       "      <td>0.076560</td>\n",
       "      <td>0.143120</td>\n",
       "      <td>0.245359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.683482</td>\n",
       "      <td>inf</td>\n",
       "      <td>458.266907</td>\n",
       "      <td>21.407169</td>\n",
       "      <td>3.016788</td>\n",
       "      <td>35.383114</td>\n",
       "      <td>5.948370</td>\n",
       "      <td>0.082559</td>\n",
       "      <td>0.116318</td>\n",
       "      <td>0.221254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.854841</td>\n",
       "      <td>inf</td>\n",
       "      <td>469.081482</td>\n",
       "      <td>21.658289</td>\n",
       "      <td>3.130225</td>\n",
       "      <td>39.579037</td>\n",
       "      <td>6.291187</td>\n",
       "      <td>0.087070</td>\n",
       "      <td>0.095490</td>\n",
       "      <td>0.205704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.988622</td>\n",
       "      <td>inf</td>\n",
       "      <td>477.489777</td>\n",
       "      <td>21.851540</td>\n",
       "      <td>3.226783</td>\n",
       "      <td>42.979313</td>\n",
       "      <td>6.555861</td>\n",
       "      <td>0.089972</td>\n",
       "      <td>0.079296</td>\n",
       "      <td>0.190132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.088787</td>\n",
       "      <td>inf</td>\n",
       "      <td>481.891052</td>\n",
       "      <td>21.952017</td>\n",
       "      <td>3.314008</td>\n",
       "      <td>45.636841</td>\n",
       "      <td>6.755505</td>\n",
       "      <td>0.093096</td>\n",
       "      <td>0.070837</td>\n",
       "      <td>0.181941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.188615</td>\n",
       "      <td>inf</td>\n",
       "      <td>487.819641</td>\n",
       "      <td>22.086639</td>\n",
       "      <td>3.387670</td>\n",
       "      <td>48.291916</td>\n",
       "      <td>6.949238</td>\n",
       "      <td>0.095938</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.174298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.257476</td>\n",
       "      <td>inf</td>\n",
       "      <td>490.938507</td>\n",
       "      <td>22.157133</td>\n",
       "      <td>3.451633</td>\n",
       "      <td>50.660896</td>\n",
       "      <td>7.117647</td>\n",
       "      <td>0.098257</td>\n",
       "      <td>0.053445</td>\n",
       "      <td>0.169262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.316076</td>\n",
       "      <td>inf</td>\n",
       "      <td>493.472778</td>\n",
       "      <td>22.214247</td>\n",
       "      <td>3.508596</td>\n",
       "      <td>52.876759</td>\n",
       "      <td>7.271641</td>\n",
       "      <td>0.100323</td>\n",
       "      <td>0.048590</td>\n",
       "      <td>0.164712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.376493</td>\n",
       "      <td>inf</td>\n",
       "      <td>496.654907</td>\n",
       "      <td>22.285755</td>\n",
       "      <td>3.564339</td>\n",
       "      <td>54.999664</td>\n",
       "      <td>7.416176</td>\n",
       "      <td>0.102056</td>\n",
       "      <td>0.042485</td>\n",
       "      <td>0.159609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.439260</td>\n",
       "      <td>inf</td>\n",
       "      <td>498.573151</td>\n",
       "      <td>22.328753</td>\n",
       "      <td>3.627903</td>\n",
       "      <td>56.821537</td>\n",
       "      <td>7.538006</td>\n",
       "      <td>0.104572</td>\n",
       "      <td>0.038815</td>\n",
       "      <td>0.156941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MAE  MAPE         MSE       RMSE  masked_MAE  masked_MSE  \\\n",
       "1    8.890697   inf  420.393372  20.503496    2.404514   18.115133   \n",
       "2    9.189088   inf  432.162567  20.788521    2.666741   25.265684   \n",
       "3    9.442976   inf  444.353088  21.079683    2.860225   30.716677   \n",
       "4    9.683482   inf  458.266907  21.407169    3.016788   35.383114   \n",
       "5    9.854841   inf  469.081482  21.658289    3.130225   39.579037   \n",
       "6    9.988622   inf  477.489777  21.851540    3.226783   42.979313   \n",
       "7   10.088787   inf  481.891052  21.952017    3.314008   45.636841   \n",
       "8   10.188615   inf  487.819641  22.086639    3.387670   48.291916   \n",
       "9   10.257476   inf  490.938507  22.157133    3.451633   50.660896   \n",
       "10  10.316076   inf  493.472778  22.214247    3.508596   52.876759   \n",
       "11  10.376493   inf  496.654907  22.285755    3.564339   54.999664   \n",
       "12  10.439260   inf  498.573151  22.328753    3.627903   56.821537   \n",
       "\n",
       "    masked_RMSE  masked_MAPE        R2      EVAR  \n",
       "1      4.256187     0.061001  0.189282  0.284271  \n",
       "2      5.026498     0.069858  0.166607  0.265751  \n",
       "3      5.542263     0.076560  0.143120  0.245359  \n",
       "4      5.948370     0.082559  0.116318  0.221254  \n",
       "5      6.291187     0.087070  0.095490  0.205704  \n",
       "6      6.555861     0.089972  0.079296  0.190132  \n",
       "7      6.755505     0.093096  0.070837  0.181941  \n",
       "8      6.949238     0.095938  0.059432  0.174298  \n",
       "9      7.117647     0.098257  0.053445  0.169262  \n",
       "10     7.271641     0.100323  0.048590  0.164712  \n",
       "11     7.416176     0.102056  0.042485  0.159609  \n",
       "12     7.538006     0.104572  0.038815  0.156941  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test TGCN cell\n",
    "model = TGCN(config,data_feature)\n",
    "\n",
    "# 加载执行器\n",
    "model_cache_file = './libcity/cache/model_cache/' + config['model'] + '_' + config['dataset'] + '.m'\n",
    "executor = get_executor(config, model)\n",
    "# 训练\n",
    "executor.train(train_data, valid_data)\n",
    "executor.save_model(model_cache_file)\n",
    "executor.load_model(model_cache_file)\n",
    "# 评估，评估结果将会放在 cache/evaluate_cache 下\n",
    "executor.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ae54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGCLSTM(AbstractTrafficStateModel):\n",
    "    def __init__(self, config, data_feature):\n",
    "        self.num_nodes = data_feature.get('num_nodes', 1)\n",
    "        self.feature_dim = data_feature.get('feature_dim', 1)\n",
    "        config['num_nodes'] = self.num_nodes\n",
    "        config['feature_dim'] = self.feature_dim\n",
    "\n",
    "        super().__init__(config, data_feature)\n",
    "        self.input_window = config.get('input_window', 1)\n",
    "        self.output_window = config.get('output_window', 1)\n",
    "        self.output_dim = self.data_feature.get('output_dim', 1)\n",
    "        self.hidden_dim = config.get('rnn_units', 64)\n",
    "        self.embed_dim = config.get('embed_dim', 10)\n",
    "\n",
    "#         self.gcn=GNN.AVWGCN(self.feature_dim,self.hidden_dim,config.get('cheb_order', 2),self.num_nodes,self.embed_dim)\n",
    "#         self.gcn_encode=GNN.TimedistributedGCN(self.gcn)\n",
    "        self.trnn=RNN.TemporalGRU(config,0,0)\n",
    "        \n",
    "        self.end_conv = nn.Conv2d(1, self.output_window * self.output_dim, kernel_size=(1, self.hidden_dim), bias=True)\n",
    "\n",
    "        self.device = config.get('device', torch.device('cpu'))\n",
    "        self._logger = getLogger()\n",
    "        self._scaler = self.data_feature.get('scaler')\n",
    "        self._init_parameters()\n",
    "    \n",
    "    def _init_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "            else:\n",
    "                nn.init.uniform_(p)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # source: B, T_1, N, D\n",
    "        # target: B, T_2, N, D\n",
    "        source = batch['X']\n",
    "        \n",
    "        batch_size=source.shape[0]\n",
    "                \n",
    "        output = self.trnn(source)  # B, T, N, hidden\n",
    "        output = output[:, -1:, :, :]                                       # B, 1, N, hidden\n",
    "\n",
    "        # CNN based predictor\n",
    "        output = self.end_conv(output)                           # B, T*C, N, 1\n",
    "        output = output.squeeze(-1).reshape(-1, self.output_window, self.output_dim, self.num_nodes)\n",
    "        output = output.permute(0, 1, 3, 2)                      # B, T, N, C\n",
    "        return output\n",
    "    \n",
    "    def calculate_loss(self, batch):\n",
    "        y_true = batch['y']\n",
    "        y_predicted = self.predict(batch)\n",
    "        y_true = self._scaler.inverse_transform(y_true[..., :self.output_dim])\n",
    "        y_predicted = self._scaler.inverse_transform(y_predicted[..., :self.output_dim])\n",
    "        return loss.masked_mae_torch(y_predicted, y_true, 0)\n",
    "\n",
    "    def predict(self, batch):\n",
    "        return self.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94101f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test TGCLSTM \n",
    "model = TGCLSTM(config,data_feature)\n",
    "\n",
    "# 加载执行器\n",
    "model_cache_file = './libcity/cache/model_cache/' + config['model'] + '_' + config['dataset'] + '.m'\n",
    "executor = get_executor(config, model)\n",
    "# 训练\n",
    "executor.train(train_data, valid_data)\n",
    "executor.save_model(model_cache_file)\n",
    "executor.load_model(model_cache_file)\n",
    "# 评估，评估结果将会放在 cache/evaluate_cache 下\n",
    "executor.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:news1] *",
   "language": "python",
   "name": "conda-env-news1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
