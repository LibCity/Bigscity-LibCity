{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fdc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/zwt/Bigscity-LibCity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7a87d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-04 13:27:40,205 - INFO - Log directory: ./libcity/log\n",
      "2021-12-04 13:27:40,205 - INFO - Log directory: ./libcity/log\n",
      "2021-12-04 13:27:40,205 - INFO - Log directory: ./libcity/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_vocab: 100%|██████████████████████████████████████| 1112156/1112156 [02:18<00:00, 8038.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14591 locations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|███████████████████████████████████████| 1112156/1112156 [03:13<00:00, 5737.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6771 users\n",
      "142 regions\n",
      "get_visited_locs...\n",
      "split dataset...\n",
      "num_neg: 5\n",
      "build LocQuerySystem...\n",
      "get train_loader...\n",
      "get test_loader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:49<00:00,  1.91s/it, loss=1.2277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 completed.\n",
      "time taken: 350.03 sec\n",
      "avg. loss: 1.5853\n",
      "epoch=1, loss=1.5853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:47<00:00,  1.90s/it, loss=1.1015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 completed.\n",
      "time taken: 348.40 sec\n",
      "avg. loss: 1.1707\n",
      "epoch=2, loss=1.1707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:54<00:00,  1.94s/it, loss=1.0127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3 completed.\n",
      "time taken: 354.61 sec\n",
      "avg. loss: 1.0668\n",
      "epoch=3, loss=1.0668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=1.0014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4 completed.\n",
      "time taken: 351.80 sec\n",
      "avg. loss: 1.0144\n",
      "epoch=4, loss=1.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:52<00:00,  1.92s/it, loss=0.9593]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5 completed.\n",
      "time taken: 352.66 sec\n",
      "avg. loss: 0.9646\n",
      "epoch=5, loss=0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:55<00:00,  1.94s/it, loss=0.8976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6 completed.\n",
      "time taken: 356.29 sec\n",
      "avg. loss: 0.9197\n",
      "epoch=6, loss=0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:53<00:00,  1.93s/it, loss=0.8826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7 completed.\n",
      "time taken: 354.09 sec\n",
      "avg. loss: 0.8854\n",
      "epoch=7, loss=0.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:52<00:00,  1.93s/it, loss=0.8316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  8 completed.\n",
      "time taken: 352.79 sec\n",
      "avg. loss: 0.8590\n",
      "epoch=8, loss=0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:52<00:00,  1.93s/it, loss=0.8465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  9 completed.\n",
      "time taken: 353.38 sec\n",
      "avg. loss: 0.8385\n",
      "epoch=9, loss=0.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=0.8267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 completed.\n",
      "time taken: 351.56 sec\n",
      "avg. loss: 0.8217\n",
      "epoch=10, loss=0.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:52<00:00,  1.92s/it, loss=0.8314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 completed.\n",
      "time taken: 352.55 sec\n",
      "avg. loss: 0.8098\n",
      "epoch=11, loss=0.8098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:49<00:00,  1.91s/it, loss=0.8001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 completed.\n",
      "time taken: 350.42 sec\n",
      "avg. loss: 0.7981\n",
      "epoch=12, loss=0.7981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.8253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 completed.\n",
      "time taken: 350.89 sec\n",
      "avg. loss: 0.7904\n",
      "epoch=13, loss=0.7904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=0.7984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 completed.\n",
      "time taken: 352.19 sec\n",
      "avg. loss: 0.7822\n",
      "epoch=14, loss=0.7822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:53<00:00,  1.93s/it, loss=0.8043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 completed.\n",
      "time taken: 353.65 sec\n",
      "avg. loss: 0.7745\n",
      "epoch=15, loss=0.7745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:52<00:00,  1.92s/it, loss=0.7866]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 completed.\n",
      "time taken: 352.66 sec\n",
      "avg. loss: 0.7693\n",
      "epoch=16, loss=0.7693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 completed.\n",
      "time taken: 350.93 sec\n",
      "avg. loss: 0.7637\n",
      "epoch=17, loss=0.7637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:53<00:00,  1.93s/it, loss=0.7928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 completed.\n",
      "time taken: 354.36 sec\n",
      "avg. loss: 0.7564\n",
      "epoch=18, loss=0.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:53<00:00,  1.93s/it, loss=0.7473]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 completed.\n",
      "time taken: 354.19 sec\n",
      "avg. loss: 0.7523\n",
      "epoch=19, loss=0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:53<00:00,  1.93s/it, loss=0.7836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 completed.\n",
      "time taken: 353.97 sec\n",
      "avg. loss: 0.7488\n",
      "epoch=20, loss=0.7488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 completed.\n",
      "time taken: 351.00 sec\n",
      "avg. loss: 0.7462\n",
      "epoch=21, loss=0.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:52<00:00,  1.92s/it, loss=0.7423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 completed.\n",
      "time taken: 352.68 sec\n",
      "avg. loss: 0.7426\n",
      "epoch=22, loss=0.7426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=0.8428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 completed.\n",
      "time taken: 351.44 sec\n",
      "avg. loss: 0.7388\n",
      "epoch=23, loss=0.7388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=0.7232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 completed.\n",
      "time taken: 351.85 sec\n",
      "avg. loss: 0.7358\n",
      "epoch=24, loss=0.7358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 completed.\n",
      "time taken: 351.35 sec\n",
      "avg. loss: 0.7326\n",
      "epoch=25, loss=0.7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:48<00:00,  1.91s/it, loss=0.7842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 completed.\n",
      "time taken: 349.26 sec\n",
      "avg. loss: 0.7312\n",
      "epoch=26, loss=0.7312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.91s/it, loss=0.7753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 completed.\n",
      "time taken: 350.55 sec\n",
      "avg. loss: 0.7283\n",
      "epoch=27, loss=0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:52<00:00,  1.93s/it, loss=0.7505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 completed.\n",
      "time taken: 352.84 sec\n",
      "avg. loss: 0.7268\n",
      "epoch=28, loss=0.7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 completed.\n",
      "time taken: 351.18 sec\n",
      "avg. loss: 0.7248\n",
      "epoch=29, loss=0.7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [06:00<00:00,  1.97s/it, loss=0.7653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 completed.\n",
      "time taken: 360.57 sec\n",
      "avg. loss: 0.7217\n",
      "epoch=30, loss=0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 completed.\n",
      "time taken: 350.93 sec\n",
      "avg. loss: 0.7192\n",
      "epoch=31, loss=0.7192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7178]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 completed.\n",
      "time taken: 351.08 sec\n",
      "avg. loss: 0.7179\n",
      "epoch=32, loss=0.7179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:55<00:00,  1.94s/it, loss=0.7125]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 completed.\n",
      "time taken: 355.61 sec\n",
      "avg. loss: 0.7167\n",
      "epoch=33, loss=0.7167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:48<00:00,  1.91s/it, loss=0.7406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34 completed.\n",
      "time taken: 349.38 sec\n",
      "avg. loss: 0.7147\n",
      "epoch=34, loss=0.7147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:54<00:00,  1.94s/it, loss=0.7654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 completed.\n",
      "time taken: 354.92 sec\n",
      "avg. loss: 0.7149\n",
      "epoch=35, loss=0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 completed.\n",
      "time taken: 351.32 sec\n",
      "avg. loss: 0.7116\n",
      "epoch=36, loss=0.7116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=0.7334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 completed.\n",
      "time taken: 351.97 sec\n",
      "avg. loss: 0.7113\n",
      "epoch=37, loss=0.7113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:52<00:00,  1.93s/it, loss=0.7624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 completed.\n",
      "time taken: 353.31 sec\n",
      "avg. loss: 0.7101\n",
      "epoch=38, loss=0.7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=0.7377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 completed.\n",
      "time taken: 352.23 sec\n",
      "avg. loss: 0.7089\n",
      "epoch=39, loss=0.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=0.6987]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40 completed.\n",
      "time taken: 351.61 sec\n",
      "avg. loss: 0.7060\n",
      "epoch=40, loss=0.7060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:54<00:00,  1.94s/it, loss=0.7358]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 completed.\n",
      "time taken: 355.07 sec\n",
      "avg. loss: 0.7046\n",
      "epoch=41, loss=0.7046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:57<00:00,  1.95s/it, loss=0.7319]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42 completed.\n",
      "time taken: 357.53 sec\n",
      "avg. loss: 0.7043\n",
      "epoch=42, loss=0.7043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:49<00:00,  1.91s/it, loss=0.7464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43 completed.\n",
      "time taken: 350.10 sec\n",
      "avg. loss: 0.7042\n",
      "epoch=43, loss=0.7042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:52<00:00,  1.92s/it, loss=0.7252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44 completed.\n",
      "time taken: 352.51 sec\n",
      "avg. loss: 0.7026\n",
      "epoch=44, loss=0.7026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:53<00:00,  1.93s/it, loss=0.7023]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 completed.\n",
      "time taken: 353.80 sec\n",
      "avg. loss: 0.7021\n",
      "epoch=45, loss=0.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:48<00:00,  1.91s/it, loss=0.7190]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46 completed.\n",
      "time taken: 349.37 sec\n",
      "avg. loss: 0.7006\n",
      "epoch=46, loss=0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7103]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47 completed.\n",
      "time taken: 351.17 sec\n",
      "avg. loss: 0.6997\n",
      "epoch=47, loss=0.6997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 183/183 [05:51<00:00,  1.92s/it, loss=0.7335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48 completed.\n",
      "time taken: 351.68 sec\n",
      "avg. loss: 0.6981\n",
      "epoch=48, loss=0.6981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:57<00:00,  1.95s/it, loss=0.6906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49 completed.\n",
      "time taken: 357.93 sec\n",
      "avg. loss: 0.6986\n",
      "epoch=49, loss=0.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [05:50<00:00,  1.92s/it, loss=0.7056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 completed.\n",
      "time taken: 350.95 sec\n",
      "avg. loss: 0.6971\n",
      "epoch=50, loss=0.6971\n",
      "training completed!\n",
      "evaluate result is  {\n",
      " \"NDCG@10\": 0.438662526047979,\n",
      " \"HR@10\": 0.650125535371437\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from libcity.data import get_dataset\n",
    "from libcity.utils import get_executor\n",
    "from libcity.utils import get_model\n",
    "from libcity.utils import get_logger\n",
    "\n",
    "config={'task': 'traj_loc_pred', 'model': 'GeoSAN', 'dataset': 'foursquare_tky', 'saved_model': True, 'train': True, 'dataset_class': 'GeoSANDataset', 'traj_encoder': 'StandardTrajectoryEncoder', 'executor': 'GeoSANExecutor', 'evaluator': 'GeoSANEvaluator', 'model_config': {'location_embedding_dim': 50, 'num_layers_encoder': 2, 'dropout': 0.5, 'region_embedding_dim': 50, 'num_heads_encoder': 1, 'user_embedding_dim': 0, 'time_embedding_dim': 0, 'hidden_dim_encoder': 0, 'num_heads_decoder': 0, 'extra_config': {'position_encoding': 'transformer', 'user_location_only': False, 'user_embedding': False, 'size_sqrt_regularize': True, 'use_attention_as_decoder': False, 'embedding_fusion': 'concat'}}, 'executor_config': {'train': {'negative_sampler': 'KNNSampler', 'negative_sampler_config': {'num_nearest': 2000, 'exclude_visited': False}, 'temperature': 1.0, 'num_negative_samples': 5, 'batch_size': 64, 'num_epochs': 50, 'num_workers': 5}, 'optimizer': {'optimizer': 'adam', 'learning_rate': 0.001}, 'test': {'negative_sampler': 'KNNSampler', 'batch_size': 32, 'num_negative_samples': 100, 'negative_sampler_config': {'num_nearest': 2000, 'exclude_visited': False}}}, 'evaluator_config': {'metrics': ['HR', 'NDCG'], 'topk': 10}, 'geo': {'including_types': ['Point'], 'Point': {'venue_category_name': 'enum'}}, 'usr': {'properties': {'gender': 'enum', 'twitter_friend_count': 'num', 'twitter_follower_count': 'num'}}, 'dyna': {'including_types': ['trajectory'], 'trajectory': {'entity_id': 'usr_id', 'location': 'geo_id', 'timezone_offset_in_minutes': 'num'}}, 'distance_upper': 30.0}\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "config['device'] = torch.device(\"cuda\")\n",
    "\n",
    "logger = get_logger(config)\n",
    "# 加载数据集\n",
    "dataset = get_dataset(config)\n",
    "# 转换数据，并划分数据集\n",
    "train_data, valid_data, test_data = dataset.get_data()\n",
    "# print(len(train_data), len(train_data.dataset), train_data.dataset[0][0].shape, train_data.dataset[0][1].shape, train_data.batch_size)\n",
    "# print(len(valid_data), len(valid_data.dataset), valid_data.dataset[0][0].shape, valid_data.dataset[0][1].shape, valid_data.batch_size)\n",
    "# print(len(test_data), len(test_data.dataset), test_data.dataset[0][0].shape, test_data.dataset[0][1].shape, test_data.batch_size)\n",
    "\n",
    "data_feature = dataset.get_data_feature()\n",
    "# print(data_feature['adj_mx'].shape)\n",
    "# print(data_feature['adj_mx'].sum())\n",
    "\n",
    "model = get_model(config, data_feature)\n",
    "\n",
    "# 加载执行器\n",
    "model_cache_file = './libcity/cache/model_cache/' + config['model'] + '_' + config['dataset'] + '.m'\n",
    "executor = get_executor(config, model)\n",
    "\n",
    "# 训练\n",
    "executor.train(train_data, valid_data)\n",
    "executor.save_model(model_cache_file)\n",
    "executor.load_model(model_cache_file)\n",
    "# 评估，评估结果将会放在 cache/evaluate_cache 下\n",
    "executor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a218aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSAN(AbstractModel):\n",
    "\n",
    "    def __init__(self, config, data_feature):\n",
    "        super().__init__(config, data_feature)\n",
    "        self.device = config['device']\n",
    "        # depend on dataset\n",
    "        self.num_neg = config['executor_config']['train']['num_negative_samples']\n",
    "        self.temperature = config['executor_config']['train']['temperature']\n",
    "\n",
    "        # from dataset\n",
    "        # from train_dataset!!\n",
    "        nuser = data_feature['nuser']\n",
    "        nloc = data_feature['nloc']\n",
    "        ntime = data_feature['ntime']\n",
    "        nquadkey = data_feature['nquadkey']\n",
    "\n",
    "        # from config\n",
    "        user_dim = int(config['model_config']['user_embedding_dim'])\n",
    "        loc_dim = int(config['model_config']['location_embedding_dim'])\n",
    "        time_dim = int(config['model_config']['time_embedding_dim'])\n",
    "        reg_dim = int(config['model_config']['region_embedding_dim'])\n",
    "        # nhid = int(config['model_config']['hidden_dim_encoder'])\n",
    "        nhead_enc = int(config['model_config']['num_heads_encoder'])\n",
    "        # nhead_dec = int(config['model_config']['num_heads_decoder'])\n",
    "        nlayers = int(config['model_config']['num_layers_encoder'])\n",
    "        dropout = float(config['model_config']['dropout'])\n",
    "        extra_config = config['model_config']['extra_config']\n",
    "        # print(f\"nloc: {nloc} \\t loc_dim: {loc_dim}\")\n",
    "        # essential\n",
    "        self.emb_loc = Embedding(nloc, loc_dim, zeros_pad=True, scale=True)\n",
    "        self.emb_reg = Embedding(nquadkey, reg_dim, zeros_pad=True, scale=True)\n",
    "        # optional\n",
    "        self.emb_user = Embedding(nuser, user_dim, zeros_pad=True, scale=True)\n",
    "        self.emb_time = Embedding(ntime, time_dim, zeros_pad=True, scale=True)\n",
    "        ninp = user_dim\n",
    "\n",
    "        pos_encoding = extra_config.get(\"position_encoding\", \"transformer\")\n",
    "        if pos_encoding == \"embedding\":\n",
    "            self.pos_encoder = PositionalEmbedding(loc_dim + reg_dim, dropout)\n",
    "        elif pos_encoding == \"transformer\":\n",
    "            self.pos_encoder = PositionalEncoding(loc_dim + reg_dim, dropout)\n",
    "        self.enc_layer = TransformerEncoderLayer(loc_dim + reg_dim, nhead_enc, loc_dim + reg_dim, dropout)\n",
    "        self.encoder = TransformerEncoder(self.enc_layer, nlayers)\n",
    "\n",
    "        self.region_pos_encoder = PositionalEmbedding(reg_dim, dropout, max_len=20)\n",
    "        self.region_enc_layer = TransformerEncoderLayer(reg_dim, 1, reg_dim, dropout=dropout)\n",
    "        self.region_encoder = TransformerEncoder(self.region_enc_layer, 2)\n",
    "\n",
    "        if not extra_config.get(\"use_location_only\", False):\n",
    "            if extra_config.get(\"embedding_fusion\", \"multiply\") == \"concat\":\n",
    "                if extra_config.get(\"user_embedding\", False):\n",
    "                    self.lin = nn.Linear(user_dim + loc_dim + reg_dim + time_dim, ninp)\n",
    "                else:\n",
    "                    self.lin = nn.Linear(loc_dim + reg_dim, ninp)\n",
    "\n",
    "        ident_mat = torch.eye(ninp)\n",
    "        self.register_buffer('ident_mat', ident_mat)\n",
    "        self.layer_norm = nn.LayerNorm(ninp)\n",
    "\n",
    "        self.extra_config = extra_config\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def predict(self, batch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch (Batch): a batch of input\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: predict result of this batch\n",
    "        \"\"\"\n",
    "        user, loc, time, region, trg, trg_reg, trg_nov, sample_probs, ds = batch\n",
    "\n",
    "        user = user.to(self.device)\n",
    "        loc = loc.to(self.device)\n",
    "        time = time.to(self.device)\n",
    "        region = region.to(self.device)\n",
    "        trg = trg.to(self.device)\n",
    "        trg_reg = trg_reg.to(self.device)\n",
    "        sample_probs = sample_probs.to(self.device)\n",
    "        src_mask = pad_sequence([torch.zeros(e, dtype=torch.bool).to(self.device) for e in ds],\n",
    "                                batch_first=True, padding_value=True)\n",
    "        att_mask = GeoSAN._generate_square_mask_(max(ds), self.device)\n",
    "\n",
    "        if self.training:\n",
    "            output = self.forward(user, loc, region, time, att_mask, src_mask,\n",
    "                                  trg, trg_reg, att_mask.repeat(self.num_neg + 1, 1))\n",
    "        else:\n",
    "            output = self.forward(user, loc, region, time, att_mask, src_mask,\n",
    "                                  trg, trg_reg, None, ds=ds)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_square_mask_(sz, device):\n",
    "        mask = (torch.triu(torch.ones(sz, sz).to(device)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def calculate_loss(self, batch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch (Batch): a batch of input\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: return training loss\n",
    "        \"\"\"\n",
    "        # only support \"WeightedProbBinaryCELoss\"\n",
    "        user, loc, time, region, trg, trg_reg, trg_nov, sample_probs, ds = batch\n",
    "\n",
    "        user = user.to(self.device)\n",
    "        loc = loc.to(self.device)\n",
    "        time = time.to(self.device)\n",
    "        region = region.to(self.device)\n",
    "        trg = trg.to(self.device)\n",
    "        trg_reg = trg_reg.to(self.device)\n",
    "        sample_probs = sample_probs.to(self.device)\n",
    "        src_mask = pad_sequence([torch.zeros(e, dtype=torch.bool).to(self.device) for e in ds],\n",
    "                                batch_first=True, padding_value=True)\n",
    "        att_mask = self._generate_square_mask_(max(ds), self.device)\n",
    "\n",
    "        if self.training:\n",
    "            output = self.forward(user, loc, region, time, att_mask, src_mask,\n",
    "                                  trg, trg_reg, att_mask.repeat(self.num_neg + 1, 1))\n",
    "        else:\n",
    "            output = self.forward(user, loc, region, time, att_mask, src_mask,\n",
    "                                  trg, trg_reg, None, ds=ds)\n",
    "\n",
    "        # shape: [(1+K)*L, N]\n",
    "        output = output.view(-1, loc.size(0), loc.size(1)).permute(2, 1, 0)\n",
    "        # shape: [N, L, 1+K]\n",
    "        pos_score, neg_score = output.split([1, self.num_neg], -1)\n",
    "        weight = F.softmax(neg_score / self.temperature - torch.log(sample_probs), -1)\n",
    "        loss = -F.logsigmoid(pos_score.squeeze()) + torch.sum(F.softplus(neg_score) * weight, dim=-1)\n",
    "        keep = pad_sequence([torch.ones(e, dtype=torch.float32).to(self.device) for e in ds], batch_first=True)\n",
    "        loss = torch.sum(loss * keep) / torch.sum(torch.tensor(ds).to(self.device))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, src_user, src_loc, src_reg, src_time,\n",
    "                src_square_mask, src_binary_mask, trg_loc, trg_reg, mem_mask, ds=None):\n",
    "        loc_emb_src = self.emb_loc(src_loc)\n",
    "        if self.extra_config.get(\"user_location_only\", False):\n",
    "            src = loc_emb_src\n",
    "        else:\n",
    "            user_emb_src = self.emb_user(src_user)\n",
    "            # (L, N, LEN_QUADKEY, REG_DIM)\n",
    "            reg_emb = self.emb_reg(src_reg)\n",
    "            reg_emb = reg_emb.view(reg_emb.size(0) * reg_emb.size(1),\n",
    "                                   reg_emb.size(2), reg_emb.size(3)).permute(1, 0, 2)\n",
    "            # (LEN_QUADKEY, L * N, REG_DIM)\n",
    "\n",
    "            reg_emb = self.region_pos_encoder(reg_emb)\n",
    "            reg_emb = self.region_encoder(reg_emb)\n",
    "            # avg pooling\n",
    "            reg_emb = torch.mean(reg_emb, dim=0)\n",
    "\n",
    "            # reg_emb, _ = self.region_gru_encoder(reg_emb, self.h_0.expand(4, reg_emb.size(1), -1).contiguous())\n",
    "            # reg_emb = reg_emb[-1, :, :]\n",
    "\n",
    "            # (L, N, REG_DIM)\n",
    "            reg_emb = reg_emb.view(loc_emb_src.size(0), loc_emb_src.size(1), reg_emb.size(1))\n",
    "\n",
    "            time_emb = self.emb_time(src_time)\n",
    "            if self.extra_config.get(\"embedding_fusion\", \"multiply\") == \"multiply\":\n",
    "                if self.extra_config.get(\"user_embedding\", False):\n",
    "                    src = loc_emb_src * reg_emb * time_emb * user_emb_src\n",
    "                else:\n",
    "                    src = loc_emb_src * reg_emb * time_emb\n",
    "            else:\n",
    "                if self.extra_config.get(\"user_embedding\", False):\n",
    "                    src = torch.cat([user_emb_src, loc_emb_src, reg_emb, time_emb], dim=-1)\n",
    "                else:\n",
    "                    src = torch.cat([loc_emb_src, reg_emb], dim=-1)\n",
    "\n",
    "        if self.extra_config.get(\"size_sqrt_regularize\", True):\n",
    "            src = src * math.sqrt(src.size(-1))\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        # shape: [L, N, ninp]\n",
    "        src = self.encoder(src, mask=src_square_mask)\n",
    "\n",
    "        # shape: [(1+K)*L, N, loc_dim]\n",
    "        loc_emb_trg = self.emb_loc(trg_loc)\n",
    "\n",
    "        reg_emb_trg = self.emb_reg(trg_reg)  # [(1+K)*L, N, LEN_QUADKEY, REG_DIM]\n",
    "        # (LEN_QUADKEY, (1+K)*L * N, REG_DIM)\n",
    "        reg_emb_trg = reg_emb_trg.view(reg_emb_trg.size(0) * reg_emb_trg.size(1),\n",
    "                                       reg_emb_trg.size(2), reg_emb_trg.size(3)).permute(1, 0, 2)\n",
    "        reg_emb_trg = self.region_pos_encoder(reg_emb_trg)\n",
    "        reg_emb_trg = self.region_encoder(reg_emb_trg)\n",
    "        reg_emb_trg = torch.mean(reg_emb_trg, dim=0)\n",
    "        # [(1+K)*L, N, REG_DIM]\n",
    "        reg_emb_trg = reg_emb_trg.view(loc_emb_trg.size(0),\n",
    "                                       loc_emb_trg.size(1), reg_emb_trg.size(1))\n",
    "\n",
    "        loc_emb_trg = torch.cat([loc_emb_trg, reg_emb_trg], dim=-1)\n",
    "        if self.extra_config.get(\"use_attention_as_decoder\", False):\n",
    "            # multi-head attention\n",
    "            output, _ = F.multi_head_attention_forward(\n",
    "                query=loc_emb_trg,\n",
    "                key=src,\n",
    "                value=src,\n",
    "                embed_dim_to_check=src.size(2),\n",
    "                num_heads=1,\n",
    "                in_proj_weight=None,\n",
    "                in_proj_bias=None,\n",
    "                bias_k=None,\n",
    "                bias_v=None,\n",
    "                add_zero_attn=None,\n",
    "                dropout_p=0.0,\n",
    "                out_proj_weight=self.ident_mat,\n",
    "                out_proj_bias=None,\n",
    "                training=self.training,\n",
    "                key_padding_mask=src_binary_mask,\n",
    "                need_weights=False,\n",
    "                attn_mask=mem_mask,\n",
    "                use_separate_proj_weight=True,\n",
    "                q_proj_weight=self.ident_mat,\n",
    "                k_proj_weight=self.ident_mat,\n",
    "                v_proj_weight=self.ident_mat\n",
    "            )\n",
    "\n",
    "            if self.training:\n",
    "                src = src.repeat(loc_emb_trg.size(0) // src.size(0), 1, 1)\n",
    "            else:\n",
    "                src = src[torch.tensor(ds) - 1, torch.arange(len(ds)), :]\n",
    "                src = src.unsqueeze(0).repeat(loc_emb_trg.size(0), 1, 1)\n",
    "\n",
    "            output += src\n",
    "            output = self.layer_norm(output)\n",
    "        else:\n",
    "            # No attention\n",
    "            if self.training:\n",
    "                output = src.repeat(loc_emb_trg.size(0) // src.size(0), 1, 1)\n",
    "            else:\n",
    "                output = src[torch.tensor(ds) - 1, torch.arange(len(ds)), :]\n",
    "                output = output.unsqueeze(0).repeat(loc_emb_trg.size(0), 1, 1)\n",
    "\n",
    "        # shape: [(1+K)*L, N]\n",
    "        output = torch.sum(output * loc_emb_trg, dim=-1)\n",
    "        return output\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:news1] *",
   "language": "python",
   "name": "conda-env-news1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
